{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da327049",
   "metadata": {},
   "source": [
    "# Assignment 11 – Part 1.2  \n",
    "## Knowledge graph construction from cleaned professor profiles\n",
    "\n",
    "This notebook:\n",
    "\n",
    "1. Loads the `cleaned_professors.json` file produced in Notebook 1.\n",
    "2. Builds a directed knowledge graph where:\n",
    "   - Each professor is a `PROFESSOR` node.\n",
    "   - Academic organizations, degrees, subjects, corporate organizations, and locations\n",
    "     become typed entity nodes.\n",
    "3. Creates labeled edges such as:\n",
    "   - **Studied at** (professor → academic organization)  \n",
    "   - **Has degree** (professor → degree)  \n",
    "   - **Teaches** (professor → subject)  \n",
    "   - **Worked at** (professor → corporate organization)  \n",
    "   - **Worked in** (professor → corporate location)\n",
    "4. Computes simple graph statistics to sanity-check the extraction.\n",
    "5. Exports the graph in GraphML, GEXF, and CSV formats for inspection in Gephi (https://lite.gephi.org/v1.0.1/)\n",
    "   and for use in the written report.\n",
    "6. Generates small visualizations (ego network + top-degree subgraph) as a quick\n",
    "   qualitative check on the resulting structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f446cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries and environment setup\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import json\n",
    "\n",
    "def ensure_package(pkg_name: str):\n",
    "    \"\"\"\n",
    "    Import a package if available; otherwise install it with pip and then import.\n",
    "    This mirrors Notebook 1 so that a fresh environment can run with 'Run All'.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        __import__(pkg_name)\n",
    "    except ImportError:\n",
    "        print(f\"Installing missing package: {pkg_name}\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg_name])\n",
    "\n",
    "# Ensure required libraries are available\n",
    "for pkg in [\"pandas\", \"networkx\", \"matplotlib\"]:\n",
    "    ensure_package(pkg)\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Load cleaned professor data generated by 01_load_and_clean.ipynb\n",
    "# ------------------------------------------------------------------\n",
    "data_path = \"../data/processed/cleaned_professors.json\"\n",
    "df = pd.read_json(data_path)\n",
    "\n",
    "print(\"Data loaded successfully from:\", data_path)\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Columns:\", list(df.columns))\n",
    "df.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e277bb33",
   "metadata": {},
   "source": [
    "## Graph schema and construction strategy\n",
    "\n",
    "Design decisions:\n",
    "\n",
    "- Use a **directed graph (`DiGraph`)** where edges always point from `PROFESSOR`\n",
    "  nodes to entity nodes. This keeps semantics simple and avoids multi-edge\n",
    "  complications for the assignment.\n",
    "- Each node carries:\n",
    "  - `label`: human-readable text (e.g., `\"Universidad Autónoma de Madrid\"`).\n",
    "  - `ntype`: node type (`PROFESSOR`, `ORG`, `EDU`, `LOC`, `SUBJECT`).\n",
    "- Each edge carries:\n",
    "  - `label` and `relation`: a concise relationship name (e.g., `\"Studied at\"`).\n",
    "- We only use **strings and simple types** for node/edge attributes so that\n",
    "  export to GraphML/GEXF (Gephi) is straightforward and does not require\n",
    "  custom parsers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bd1231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Build nodes and labeled edges from professor_dict\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# 1) Create professor nodes\n",
    "for i, row in df.iterrows():\n",
    "    prof_id = f\"PROF_{i}\"\n",
    "    if not G.has_node(prof_id):\n",
    "        G.add_node(prof_id, label=f\"Professor {i}\", ntype=\"PROFESSOR\")\n",
    "\n",
    "# 2) Helper to create / reuse entity nodes\n",
    "def add_entity_node(name: str, ntype: str):\n",
    "    if not name:\n",
    "        return None\n",
    "    node_id = f\"{ntype}:{name}\"\n",
    "    if not G.has_node(node_id):\n",
    "        G.add_node(node_id, label=name, ntype=ntype)\n",
    "    return node_id\n",
    "\n",
    "# 3) Helper to add a typed relation from professor to entity\n",
    "def add_relation(prof_id: str, target_label: str, target_type: str, relation_label: str):\n",
    "    target_id = add_entity_node(target_label, target_type)\n",
    "    if target_id is None:\n",
    "        return\n",
    "    # For DiGraph, repeated calls will overwrite attributes rather than duplicate edges,\n",
    "    # which is fine here because relation_label is deterministic.\n",
    "    G.add_edge(prof_id, target_id, label=relation_label, relation=relation_label)\n",
    "\n",
    "# 4) Iterate over the dataframe and add semantic edges\n",
    "for i, row in df.iterrows():\n",
    "    prof_id = f\"PROF_{i}\"\n",
    "    d = row[\"professor_dict\"]\n",
    "\n",
    "    # Academic background\n",
    "    for org in d.get(\"Academic Background - Organization\", []):\n",
    "        add_relation(prof_id, org, \"ORG\", \"Studied at\")\n",
    "    for edu in d.get(\"Academic Background - Education\", []):\n",
    "        add_relation(prof_id, edu, \"EDU\", \"Has degree\")\n",
    "\n",
    "    # Teaching / subjects\n",
    "    for subj in d.get(\"Academic Experience - Subjects\", []):\n",
    "        add_relation(prof_id, subj, \"SUBJECT\", \"Teaches\")\n",
    "\n",
    "    # Corporate experience\n",
    "    for org in d.get(\"Corporate Experience - Organization\", []):\n",
    "        add_relation(prof_id, org, \"ORG\", \"Worked at\")\n",
    "    for loc in d.get(\"Corporate Experience - Location\", []):\n",
    "        add_relation(prof_id, loc, \"LOC\", \"Worked in\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3da449b",
   "metadata": {},
   "source": [
    "## Sanity checks: node/edge counts and high-degree entities\n",
    "\n",
    "Before exporting the graph, I compute basic statistics to confirm that:\n",
    "\n",
    "- The expected node types are present (professors, organizations, locations, etc.).\n",
    "- The total number of edges is reasonable given the dataset size.\n",
    "- High-degree organizations and locations (e.g., major universities or “Spain”)\n",
    "  show up as central hubs, which matches domain expectations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391007cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Quick statistics on the constructed graph\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "node_types = pd.Series(nx.get_node_attributes(G, \"ntype\")).value_counts()\n",
    "print(\"Node counts by type:\\n\", node_types.to_string(), \"\\n\")\n",
    "print(\"Total nodes:\", G.number_of_nodes(), \"  Total edges:\", G.number_of_edges())\n",
    "\n",
    "# Top connected organizations and locations\n",
    "deg = dict(G.degree())\n",
    "top_orgs = sorted(\n",
    "    [(n, deg[n]) for n, d in G.nodes(data=True) if d.get(\"ntype\") == \"ORG\"],\n",
    "    key=lambda x: x[1],\n",
    "    reverse=True,\n",
    ")[:15]\n",
    "\n",
    "top_locs = sorted(\n",
    "    [(n, deg[n]) for n, d in G.nodes(data=True) if d.get(\"ntype\") == \"LOC\"],\n",
    "    key=lambda x: x[1],\n",
    "    reverse=True,\n",
    ")[:15]\n",
    "\n",
    "print(\"\\nTop ORGs by degree:\")\n",
    "labels = nx.get_node_attributes(G, \"label\")\n",
    "for n, k in top_orgs:\n",
    "    print(labels.get(n, n), \"->\", k)\n",
    "\n",
    "print(\"\\nTop LOCs by degree:\")\n",
    "for n, k in top_locs:\n",
    "    print(labels.get(n, n), \"->\", k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a91d53d",
   "metadata": {},
   "source": [
    "## Exporting the graph for Gephi and downstream analysis\n",
    "\n",
    "I export the graph in multiple formats:\n",
    "\n",
    "- **GraphML** and **GEXF** for Gephi and other graph tools.\n",
    "- **nodes.csv** and **edges.csv** for tabular inspection and to reference in the report.\n",
    "\n",
    "To keep these exports robust, I coerce all node and edge attributes to\n",
    "simple types (strings, numbers, booleans, or `None`). This avoids GraphML\n",
    "errors about unsupported Python objects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03133857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Export graph artifacts (GraphML, GEXF, and CSV)\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "os.makedirs(\"../outputs/graph\", exist_ok=True)\n",
    "\n",
    "def _coerce_for_graphml(v):\n",
    "    if isinstance(v, (set, list, dict, tuple)):\n",
    "        # store as JSON-like string so it is still readable if needed\n",
    "        return json.dumps(v, ensure_ascii=False)\n",
    "    if isinstance(v, (str, int, float, bool)) or v is None:\n",
    "        return v\n",
    "    return str(v)\n",
    "\n",
    "# Sanitize attributes in-place\n",
    "for _, data in G.nodes(data=True):\n",
    "    for k in list(data.keys()):\n",
    "        data[k] = _coerce_for_graphml(data[k])\n",
    "\n",
    "for _, _, data in G.edges(data=True):\n",
    "    for k in list(data.keys()):\n",
    "        data[k] = _coerce_for_graphml(data[k])\n",
    "\n",
    "# GraphML and GEXF for Gephi\n",
    "graphml_path = \"../outputs/graph/prof_kg.graphml\"\n",
    "gexf_path    = \"../outputs/graph/prof_kg.gexf\"\n",
    "\n",
    "nx.write_graphml(G, graphml_path)\n",
    "nx.write_gexf(G, gexf_path)\n",
    "\n",
    "# Node and edge tables for the report\n",
    "nodes_df = pd.DataFrame(\n",
    "    [(n, d.get(\"label\"), d.get(\"ntype\")) for n, d in G.nodes(data=True)],\n",
    "    columns=[\"node_id\", \"label\", \"type\"],\n",
    ")\n",
    "\n",
    "edges_df = pd.DataFrame(\n",
    "    [(u, v, d.get(\"relation\")) for u, v, d in G.edges(data=True)],\n",
    "    columns=[\"source\", \"target\", \"relation\"],\n",
    ")\n",
    "\n",
    "nodes_csv_path = \"../outputs/graph/nodes.csv\"\n",
    "edges_csv_path = \"../outputs/graph/edges.csv\"\n",
    "\n",
    "nodes_df.to_csv(nodes_csv_path, index=False)\n",
    "edges_df.to_csv(edges_csv_path, index=False)\n",
    "\n",
    "print(\"\\nSaved graph artifacts:\")\n",
    "print(\" -\", graphml_path)\n",
    "print(\" -\", gexf_path)\n",
    "print(\" -\", nodes_csv_path)\n",
    "print(\" -\", edges_csv_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389151ac",
   "metadata": {},
   "source": [
    "## Visual sanity checks\n",
    "\n",
    "To complement the numeric statistics, I plot:\n",
    "\n",
    "1. A **1-hop ego network** around a sample professor to see if the local\n",
    "   neighborhood matches the intended schema (professor → orgs, degrees,\n",
    "   locations, subjects).\n",
    "2. A **subgraph of the top-degree nodes** to inspect the global structure\n",
    "   and visually confirm that major universities and locations act as hubs.\n",
    "\n",
    "These plots are not meant to be publication-ready but help catch obvious\n",
    "graph construction errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d180f77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Visual sanity checks: ego network and top-degree subgraph\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "# 1) Example professor ego network (1-hop)\n",
    "try:\n",
    "    sample_prof = next(n for n, d in G.nodes(data=True) if d.get(\"ntype\") == \"PROFESSOR\")\n",
    "    ego = nx.ego_graph(G, sample_prof, radius=1)\n",
    "\n",
    "    plt.figure(figsize=(9, 7))\n",
    "    pos = nx.spring_layout(ego, seed=42)\n",
    "\n",
    "    type_colors = {\n",
    "        \"PROFESSOR\": \"tab:blue\",\n",
    "        \"ORG\": \"tab:green\",\n",
    "        \"LOC\": \"tab:orange\",\n",
    "        \"EDU\": \"tab:purple\",\n",
    "        \"SUBJECT\": \"tab:red\",\n",
    "    }\n",
    "\n",
    "    node_colors = [\n",
    "        type_colors.get(G.nodes[n].get(\"ntype\"), \"tab:gray\") for n in ego.nodes()\n",
    "    ]\n",
    "\n",
    "    nx.draw(\n",
    "        ego,\n",
    "        pos,\n",
    "        with_labels=True,\n",
    "        labels=nx.get_node_attributes(ego, \"label\"),\n",
    "        node_color=node_colors,\n",
    "        node_size=400,\n",
    "        font_size=8,\n",
    "    )\n",
    "    plt.title(\"Example professor ego network (1 hop)\")\n",
    "    plt.show()\n",
    "except StopIteration:\n",
    "    print(\"No professor nodes to visualize.\")\n",
    "\n",
    "# 2) Subgraph of top 200 most connected nodes\n",
    "sub_nodes = sorted(G.degree, key=lambda x: x[1], reverse=True)[:200]\n",
    "H = G.subgraph([n for n, _ in sub_nodes])\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "pos = nx.spring_layout(H, seed=42)\n",
    "nx.draw(\n",
    "    H,\n",
    "    pos,\n",
    "    with_labels=False,\n",
    "    node_size=30,\n",
    "    edge_color=\"gray\",\n",
    "    alpha=0.6,\n",
    ")\n",
    "plt.title(\"Sample knowledge graph (top 200 nodes by degree)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7874e3",
   "metadata": {},
   "source": [
    "## Optional: export a smaller sample graph for faster Gephi exploration\n",
    "\n",
    "The full graph can still be somewhat heavy in Gephi. As an optional step,\n",
    "I export a smaller subgraph containing only the top-degree nodes. This\n",
    "makes it easier to experiment with layouts and styling while keeping the\n",
    "core structure of the network.\n",
    "\n",
    "View the graph using Gephi! https://lite.gephi.org/v1.0.1/. I figure this is easier than viewing it within the IDE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dff30eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Export a smaller sample subgraph for quick Gephi experiments\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "sample_nodes = sorted(G.degree, key=lambda x: x[1], reverse=True)[:50]\n",
    "H = G.subgraph([n for n, _ in sample_nodes]).copy()\n",
    "\n",
    "os.makedirs(\"../outputs/graph\", exist_ok=True)\n",
    "sample_path = \"../outputs/graph/prof_kg_sample.graphml\"\n",
    "\n",
    "# Attributes should already be GraphML-safe, but we coerce again defensively\n",
    "for _, data in H.nodes(data=True):\n",
    "    for k in list(data.keys()):\n",
    "        data[k] = _coerce_for_graphml(data[k])\n",
    "\n",
    "for _, _, data in H.edges(data=True):\n",
    "    for k in list(data.keys()):\n",
    "        data[k] = _coerce_for_graphml(data[k])\n",
    "\n",
    "nx.write_graphml(H, sample_path)\n",
    "\n",
    "print(f\"Sample graph saved to: {sample_path}\")\n",
    "print(f\"Sample nodes: {H.number_of_nodes()}   Sample edges: {H.number_of_edges()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

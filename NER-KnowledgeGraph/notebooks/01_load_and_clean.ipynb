{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c6360f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"../data/raw/teachers_db_practice.csv\")\n",
    "\n",
    "# Take a quick look\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4d2b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "print(df.loc[0, \"full_info\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ee9c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Remove HTML tags and extra whitespace\n",
    "df[\"clean_text\"] = (\n",
    "    df[\"full_info\"]\n",
    "    .fillna(\"\")\n",
    "    .apply(lambda x: re.sub(r\"<.*?>\", \" \", x))\n",
    "    .apply(lambda x: re.sub(r\"\\s+\", \" \", x).strip())\n",
    ")\n",
    "\n",
    "df[\"clean_text\"].head(3).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11396d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Extract sections from the original HTML-ish text ----\n",
    "import re\n",
    "\n",
    "SECTION_HEADERS = {\n",
    "    \"corp\": r\"(?:<h4>\\s*CORPORATE EXPERIENCE\\s*</h4>|CORPORATE EXPERIENCE)\",\n",
    "    \"acadexp\": r\"(?:<h4>\\s*ACADEMIC EXPERIENCE\\s*</h4>|ACADEMIC EXPERIENCE)\",\n",
    "    \"acadbg\": r\"(?:<h4>\\s*ACADEMIC BACKGROUND\\s*</h4>|ACADEMIC BACKGROUND)\",\n",
    "}\n",
    "\n",
    "def strip_html(s: str) -> str:\n",
    "    if not isinstance(s, str):\n",
    "        return \"\"\n",
    "    # fix common &amp; noise then strip tags\n",
    "    s = re.sub(r\"&\\s*amp;?\", \"&\", s, flags=re.I)\n",
    "    s = re.sub(r\"<.*?>\", \" \", s)              # remove tags\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def extract_sections(raw: str):\n",
    "    text = raw if isinstance(raw, str) else \"\"\n",
    "    # Normalize case for header matching but keep original for content slicing\n",
    "    low = text.lower()\n",
    "\n",
    "    def find_idx(pattern):\n",
    "        m = re.search(pattern, text, flags=re.I)\n",
    "        return m.start() if m else None\n",
    "\n",
    "    i_corp = find_idx(SECTION_HEADERS[\"corp\"])\n",
    "    i_acadexp = find_idx(SECTION_HEADERS[\"acadexp\"])\n",
    "    i_acadbg = find_idx(SECTION_HEADERS[\"acadbg\"])\n",
    "\n",
    "    # helper to slice safely\n",
    "    def slice_between(start, end):\n",
    "        if start is None:\n",
    "            return \"\"\n",
    "        end = len(text) if end is None else end\n",
    "        return strip_html(text[start:end])\n",
    "\n",
    "    # determine boundaries\n",
    "    idxs = sorted([(k, v) for k, v in [(\"corp\", i_corp), (\"acadexp\", i_acadexp), (\"acadbg\", i_acadbg)] if v is not None],\n",
    "                  key=lambda x: x[1])\n",
    "    corp_txt = acadexp_txt = acadbg_txt = \"\"\n",
    "    if idxs:\n",
    "        # walk through in order and slice to next header\n",
    "        for j, (label, start) in enumerate(idxs):\n",
    "            end = idxs[j+1][1] if j+1 < len(idxs) else None\n",
    "            chunk = slice_between(start, end)\n",
    "            if label == \"corp\": corp_txt = chunk\n",
    "            elif label == \"acadexp\": acadexp_txt = chunk\n",
    "            elif label == \"acadbg\": acadbg_txt = chunk\n",
    "    else:\n",
    "        # fallback: no headers -> treat all as one generic blob (will still be used if needed)\n",
    "        corp_txt = strip_html(text)\n",
    "\n",
    "    return pd.Series({\n",
    "        \"corp_text\": corp_txt,\n",
    "        \"acadexp_text\": acadexp_txt,\n",
    "        \"acadbg_text\": acadbg_txt\n",
    "    })\n",
    "\n",
    "sec_df = df[\"full_info\"].apply(extract_sections)\n",
    "df = pd.concat([df, sec_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b3db90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load a pre-trained NER model\n",
    "ner = pipeline(\"ner\", model=\"dslim/bert-base-NER\", aggregation_strategy=\"simple\")\n",
    "\n",
    "# Test on small sample of dataset\n",
    "sample_text = df.loc[1, \"clean_text\"]\n",
    "ner_results = ner(sample_text[:1000])  # limit to 1000 chars just to test\n",
    "ner_results[:10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be12dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "df[\"entities\"] = df[\"clean_text\"].progress_apply(lambda x: ner(x[:2000]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c2a694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Run NER per section (safer for dict building) ----\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "def run_ner_safe(s, limit=2000):\n",
    "    s = s if isinstance(s, str) else \"\"\n",
    "    return ner(s[:limit]) if s else []\n",
    "\n",
    "df[\"entities_corp\"]    = df[\"corp_text\"].progress_apply(run_ner_safe)\n",
    "df[\"entities_acadexp\"] = df[\"acadexp_text\"].progress_apply(run_ner_safe)\n",
    "df[\"entities_acadbg\"]  = df[\"acadbg_text\"].progress_apply(run_ner_safe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f444ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "def normalize_entities(entities):\n",
    "    cleaned = []\n",
    "    for ent in entities:\n",
    "        word = ent[\"word\"].strip()\n",
    "        # Remove stray punctuation and unify case\n",
    "        word = word.replace(\".\", \"\").replace(\",\", \"\").title()\n",
    "        cleaned.append((ent[\"entity_group\"], word))\n",
    "    return cleaned\n",
    "\n",
    "df[\"normalized_entities\"] = df[\"entities\"].apply(normalize_entities)\n",
    "df[\"normalized_entities\"].head(2).values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c2574c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acb83ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "LOCATION_MAP = {\n",
    "    \"us\": \"United States\",\n",
    "    \"usa\": \"United States\",\n",
    "    \"u.s.\": \"United States\",\n",
    "    \"u.k.\": \"United Kingdom\",\n",
    "    \"uk\": \"United Kingdom\",\n",
    "    \"spain\": \"Spain\",\n",
    "    \"madrid\": \"Madrid\",\n",
    "    \"mexico\": \"Mexico\",\n",
    "    \"mexico city\": \"Mexico City\",\n",
    "    \"london\": \"London\",\n",
    "    \"paris\": \"Paris\",\n",
    "    \"france\": \"France\",\n",
    "    \"germany\": \"Germany\",\n",
    "    \"italy\": \"Italy\",\n",
    "    \"portugal\": \"Portugal\",\n",
    "    \"barcelona\": \"Barcelona\",\n",
    "    \"new york\": \"New York\",\n",
    "}\n",
    "\n",
    "ORG_FIXES = {\n",
    "    # IE ecosystem\n",
    "    \"ie\": \"IE\",\n",
    "    \"ie university\": \"IE\",\n",
    "    \"ie business school\": \"IE\",\n",
    "    \"ie law school\": \"IE\",\n",
    "    \"instituto de empresa\": \"IE\",\n",
    "    \"ie school of global and public affairs\": \"IE\",\n",
    "    # Spanish universities\n",
    "    \"universidad autonoma de madrid\": \"Universidad Autónoma de Madrid\",\n",
    "    \"uam\": \"Universidad Autónoma de Madrid\",\n",
    "    \"universidad complutense de madrid\": \"Universidad Complutense de Madrid\",\n",
    "    \"universidad carlos iii de madrid\": \"Universidad Carlos III de Madrid\",\n",
    "    \"universidad politecnica de madrid\": \"Universidad Politécnica de Madrid\",\n",
    "    \"universidad de navarra\": \"Universidad de Navarra\",\n",
    "    \"universidad pontificia comillas\": \"Universidad Pontificia Comillas\",\n",
    "    \"comillas university\": \"Universidad Pontificia Comillas\",\n",
    "    \"icade\": \"Universidad Pontificia Comillas\",\n",
    "    \"iese business school\": \"IESE Business School\",\n",
    "    # companies / misc\n",
    "    \"a & am\": \"A&M Studio\",\n",
    "    \"a&m\": \"A&M Studio\",\n",
    "    \"am studio\": \"A&M Studio\",\n",
    "}\n",
    "\n",
    "GENERIC_ORG_WORDS = {\n",
    "    \"academic\", \"academic exp\", \"academ\", \"experience\", \"exp\",\n",
    "    \"university\", \"universidad\", \"engineering\", \"design\",\n",
    "    \"academy\", \"school\", \"faculty\", \"department\", \"college\",\n",
    "    \"education\", \"institute\", \"business\", \"finance\", \"management\",\n",
    "    \"administration\", \"economics\", \"marketing\", \"law\", \"science\",\n",
    "    \"technology\", \"research\", \"professor\", \"lecturer\"\n",
    "}\n",
    "\n",
    "def normalize_entities(entities):\n",
    "    cleaned = []\n",
    "    for ent in entities:\n",
    "        text = ent[\"word\"].lower().strip()\n",
    "        text = re.sub(r\"[^a-z0-9&.\\sáéíóúüñ]\", \"\", text)\n",
    "        text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "        if len(text) < 3:\n",
    "            continue\n",
    "\n",
    "        if ent[\"entity_group\"] == \"LOC\":\n",
    "            text = LOCATION_MAP.get(text, text.title())\n",
    "\n",
    "        elif ent[\"entity_group\"] == \"ORG\":\n",
    "            text = ORG_FIXES.get(text, text.title())\n",
    "\n",
    "            # drop headings and generic garbage\n",
    "            if (\n",
    "                text.lower() in GENERIC_ORG_WORDS\n",
    "                or len(text.split()) == 1 and text.lower() not in [v.lower() for v in ORG_FIXES.values()]\n",
    "            ):\n",
    "                continue\n",
    "\n",
    "        else:\n",
    "            text = text.title()\n",
    "\n",
    "        cleaned.append((ent[\"entity_group\"], text))\n",
    "    return cleaned\n",
    "\n",
    "df[\"normalized_entities\"] = df[\"entities\"].apply(normalize_entities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287f153e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Normalize per section ----\n",
    "df[\"norm_corp\"]    = df[\"entities_corp\"].apply(normalize_entities)\n",
    "df[\"norm_acadexp\"] = df[\"entities_acadexp\"].apply(normalize_entities)\n",
    "df[\"norm_acadbg\"]  = df[\"entities_acadbg\"].apply(normalize_entities)\n",
    "\n",
    "# Optional: fuzzy consolidate inside each section\n",
    "df = consolidate_similar_entities(df, \"ORG\", threshold=90)  # keeps df[\"normalized_entities\"], but we’ll use the sectioned cols\n",
    "# (If you want the consolidate step section-specific, you can skip it here; your maps already did most of the work.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b71db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- SECTION-AWARE EXTRACTION (place directly under the last normalized_entities assignment) --------\n",
    "import re\n",
    "from html import unescape\n",
    "\n",
    "def _extract_section(html_text, header):\n",
    "    \"\"\"Grab text under <h4>HEADER</h4> until the next <h4> or end.\"\"\"\n",
    "    if not isinstance(html_text, str):\n",
    "        return \"\"\n",
    "    s = unescape(html_text)  # fixes '&amp;' -> '&' so we don't get '& Am'\n",
    "    # capture everything after this header up to next <h4> or end\n",
    "    m = re.search(rf\"<h4>\\s*{header}\\s*</h4>(.*?)(?=<h4>|$)\", s, flags=re.I|re.S)\n",
    "    if not m:\n",
    "        return \"\"\n",
    "    # strip tags but keep text\n",
    "    body = re.sub(r\"<.*?>\", \" \", m.group(1))\n",
    "    body = re.sub(r\"\\s+\", \" \", body).strip()\n",
    "    return body\n",
    "\n",
    "# 1) Parse sections from the original HTML (not the stripped text)\n",
    "df[\"section_corporate\"] = df[\"full_info\"].apply(lambda x: _extract_section(x, \"CORPORATE EXPERIENCE\"))\n",
    "df[\"section_acad_exp\"]  = df[\"full_info\"].apply(lambda x: _extract_section(x, \"ACADEMIC EXPERIENCE\"))\n",
    "df[\"section_acad_bg\"]   = df[\"full_info\"].apply(lambda x: _extract_section(x, \"ACADEMIC BACKGROUND\"))\n",
    "\n",
    "# 2) Run NER per section (short-circuit empty strings; limit length to be laptop-friendly)\n",
    "def _safe_ner(txt):\n",
    "    if not txt:\n",
    "        return []\n",
    "    return ner(txt[:2000])  # reuse your existing HF pipeline\n",
    "\n",
    "df[\"corp_entities\"] = df[\"section_corporate\"].apply(_safe_ner)\n",
    "df[\"acadexp_entities\"] = df[\"section_acad_exp\"].apply(_safe_ner)\n",
    "df[\"acadbg_entities\"] = df[\"section_acad_bg\"].apply(_safe_ner)\n",
    "\n",
    "# 3) Reuse your normalization on each section\n",
    "df[\"corp_norm\"]    = df[\"corp_entities\"].apply(normalize_entities)\n",
    "df[\"acadexp_norm\"] = df[\"acadexp_entities\"].apply(normalize_entities)\n",
    "df[\"acadbg_norm\"]  = df[\"acadbg_entities\"].apply(normalize_entities)\n",
    "\n",
    "# 4) Build the assignment-style dictionary PER PROFESSOR using sectioned entities\n",
    "def _pick(ents, label): \n",
    "    return [e[1] for e in ents if e[0] == label]\n",
    "\n",
    "def build_professor_dict_from_sections(row):\n",
    "    corp, aexp, abg = row[\"corp_norm\"], row[\"acadexp_norm\"], row[\"acadbg_norm\"]\n",
    "    return {\n",
    "        \"Corporate Experience - Organization\": _pick(corp, \"ORG\"),\n",
    "        \"Corporate Experience - Location\":     _pick(corp, \"LOC\"),\n",
    "        \"Academic Background - Organization\":  _pick(abg,  \"ORG\"),\n",
    "        \"Academic Background - Education\":     [],   # optional: fill later with regex/keywords\n",
    "        \"Academic Experience - Courses\":       [],   # optional\n",
    "        \"Academic Experience - Subjects\":      []    # optional\n",
    "    }\n",
    "\n",
    "df[\"professor_dict\"] = df.apply(build_professor_dict_from_sections, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3c9d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Auto-alias clustering for ORG/LOC without hardcoding ---\n",
    "\n",
    "import unicodedata\n",
    "from collections import Counter, defaultdict\n",
    "from rapidfuzz import fuzz, process\n",
    "\n",
    "def simplify_for_match(s: str) -> str:\n",
    "    # lowercase, strip accents, remove stop words like university/universidad/etc., collapse spaces\n",
    "    s0 = s.lower().strip()\n",
    "    s0 = \"\".join(c for c in unicodedata.normalize(\"NFKD\", s0) if not unicodedata.combining(c))\n",
    "    s0 = s0.replace(\"&\", \"and\")\n",
    "    # drop very generic words in many languages\n",
    "    drop = {\"university\",\"universidad\",\"universite\",\"università\",\"universita\",\"universidade\",\n",
    "            \"school\",\"college\",\"institute\",\"instituto\",\"universidad\",\"dept\",\"department\"}\n",
    "    tokens = [t for t in re.sub(r\"[^a-z0-9\\s]\", \" \", s0).split() if t not in drop]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# collect all ORG/LOC surface forms\n",
    "all_orgs = []\n",
    "all_locs = []\n",
    "for row in df[\"normalized_entities\"]:\n",
    "    for typ, val in row:\n",
    "        if typ == \"ORG\":\n",
    "            all_orgs.append(val)\n",
    "        elif typ == \"LOC\":\n",
    "            all_locs.append(val)\n",
    "\n",
    "def build_alias_map(names, sim_threshold=92):\n",
    "    names = list(set(names))\n",
    "    # group by simplified key first (fast win)\n",
    "    buckets = defaultdict(list)\n",
    "    for n in names:\n",
    "        buckets[simplify_for_match(n)].append(n)\n",
    "\n",
    "    alias_map = {}\n",
    "\n",
    "    # within each bucket, pick the most common as canonical; also fuzzy-merge near buckets\n",
    "    # pick canonical = most frequent original form\n",
    "    freq = Counter(names)\n",
    "\n",
    "    # first pass: intra-bucket\n",
    "    for _, variants in buckets.items():\n",
    "        canonical = max(variants, key=lambda x: freq[x])\n",
    "        for v in variants:\n",
    "            alias_map[v] = canonical\n",
    "\n",
    "    # second pass: inter-bucket fuzzy consolidation of canonicals\n",
    "    canonicals = list(set(alias_map[v] for v in alias_map))\n",
    "    for c in canonicals:\n",
    "        # find nearest other canonicals by token_sort_ratio\n",
    "        matches = process.extract(c, canonicals, scorer=fuzz.token_sort_ratio, limit=5)\n",
    "        for other, score, _ in matches:\n",
    "            if other != c and score >= sim_threshold:\n",
    "                # unify to the most frequent of the two\n",
    "                winner = c if freq[c] >= freq[other] else other\n",
    "                loser  = other if winner == c else c\n",
    "                # redirect all aliases pointing to loser → winner\n",
    "                for k, v in list(alias_map.items()):\n",
    "                    if v == loser:\n",
    "                        alias_map[k] = winner\n",
    "                # also update the canonical list\n",
    "                canonicals = [winner if x == loser else x for x in canonicals]\n",
    "\n",
    "    return alias_map\n",
    "\n",
    "ORG_ALIAS = build_alias_map(all_orgs, sim_threshold=92)\n",
    "LOC_ALIAS = build_alias_map(all_locs, sim_threshold=95)\n",
    "\n",
    "def apply_aliases(entities):\n",
    "    out = []\n",
    "    for typ, val in entities:\n",
    "        if typ == \"ORG\":\n",
    "            out.append((typ, ORG_ALIAS.get(val, val)))\n",
    "        elif typ == \"LOC\":\n",
    "            out.append((typ, LOC_ALIAS.get(val, val)))\n",
    "        else:\n",
    "            out.append((typ, val))\n",
    "    return out\n",
    "\n",
    "df[\"normalized_entities\"] = df[\"normalized_entities\"].apply(apply_aliases)\n",
    "\n",
    "# --- Build per-professor property dictionaries based on sections ---\n",
    "\n",
    "SECTION_KEYS = {\n",
    "    \"corporate\": [\"<h4>corporate experience</h4>\", \"corporate experience\"],\n",
    "    \"academic_exp\": [\"<h4>academic experience</h4>\", \"academic experience\"],\n",
    "    \"academic_bg\": [\"<h4>academic background</h4>\", \"academic background\"],\n",
    "}\n",
    "\n",
    "DEGREE_PAT = re.compile(\n",
    "    r\"\\b(ph\\.?d|doctorate|msc|m\\.sc\\.|ms|ma|m\\.a\\.|mba|bsc|b\\.sc\\.|bs|ba|b\\.a\\.|llm|jd|md)\\b\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "# light list of subjects to catch common terms (extend later if you want)\n",
    "SUBJECT_PAT = re.compile(\n",
    "    r\"\\b(machine learning|quantum physics|mathematics|finance|economics|marketing|law|computer science|data science)\\b\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "def get_sections(raw_html_or_text:str):\n",
    "    \"\"\"Return dict with text per section; robust to having tags removed or present.\"\"\"\n",
    "    t = raw_html_or_text or \"\"\n",
    "    t_l = t.lower()\n",
    "    # find start indices\n",
    "    idx = {}\n",
    "    for key, variants in SECTION_KEYS.items():\n",
    "        for v in variants:\n",
    "            p = t_l.find(v)\n",
    "            if p != -1:\n",
    "                idx[key] = p\n",
    "                break\n",
    "    # slice text by nearest next section\n",
    "    order = [k for k in [\"corporate\",\"academic_exp\",\"academic_bg\"] if k in idx]\n",
    "    out = {\"corporate\":\"\", \"academic_exp\":\"\", \"academic_bg\":\"\"}\n",
    "    for i,k in enumerate(order):\n",
    "        start = idx[k]\n",
    "        end = idx[order[i+1]] if i+1 < len(order) else len(t)\n",
    "        out[k] = re.sub(r\"<.*?>\",\" \", t[start:end])  # strip tags inside slice\n",
    "    # fallback: if nothing matched, put everything in academic_exp to not lose info\n",
    "    if not any(out.values()):\n",
    "        out[\"academic_exp\"] = re.sub(r\"<.*?>\",\" \", t)\n",
    "    # compact whitespace\n",
    "    for k in out:\n",
    "        out[k] = re.sub(r\"\\s+\",\" \", out[k]).strip()\n",
    "    return out\n",
    "\n",
    "def build_property_dict(row):\n",
    "    sections = get_sections(row.get(\"full_info\",\"\") or row.get(\"clean_text\",\"\"))\n",
    "    ents = row[\"normalized_entities\"]\n",
    "\n",
    "    def pick_in(section_text, typ):\n",
    "        hits = []\n",
    "        S = section_text.lower()\n",
    "        for t, val in ents:\n",
    "            if t != typ: \n",
    "                continue\n",
    "            v = val.lower()\n",
    "            # string containment as a simple attribution heuristic\n",
    "            if v and v in S and val not in hits:\n",
    "                hits.append(val)\n",
    "        return hits\n",
    "\n",
    "    corp_orgs = pick_in(sections[\"corporate\"], \"ORG\")\n",
    "    corp_locs = pick_in(sections[\"corporate\"], \"LOC\")\n",
    "    acad_bg_orgs = pick_in(sections[\"academic_bg\"], \"ORG\")\n",
    "    acad_exp_orgs = pick_in(sections[\"academic_exp\"], \"ORG\")\n",
    "    acad_exp_locs = pick_in(sections[\"academic_exp\"], \"LOC\")\n",
    "\n",
    "    # Education (simple regex on academic background section)\n",
    "    education = list({m.group(0).upper().replace(\".\", \"\") for m in DEGREE_PAT.finditer(sections[\"academic_bg\"])})\n",
    "\n",
    "    # Subjects (keywords from academic experience)\n",
    "    subjects = list({m.group(0).title() for m in SUBJECT_PAT.finditer(sections[\"academic_exp\"])})\n",
    "\n",
    "    return {\n",
    "        \"Corporate Experience - Location\": corp_locs,\n",
    "        \"Corporate Experience - Organization\": corp_orgs,\n",
    "        \"Academic Background - Organization\": acad_bg_orgs,\n",
    "        \"Academic Background - Education\": education,\n",
    "        \"Academic Experience - Courses\": [],  # optional—can be filled later if you choose\n",
    "        \"Academic Experience - Subjects\": subjects,\n",
    "    }\n",
    "\n",
    "df[\"property_dict\"] = df.apply(build_property_dict, axis=1)\n",
    "df[\"property_dict\"].head(2).to_dict()\n",
    "\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "org_counts = Counter([e[1] for row in df[\"normalized_entities\"] for e in row if e[0] == \"ORG\"])\n",
    "loc_counts = Counter([e[1] for row in df[\"normalized_entities\"] for e in row if e[0] == \"LOC\"])\n",
    "\n",
    "print(\"Top ORGs:\", org_counts.most_common(10))\n",
    "print(\"Top LOCs:\", loc_counts.most_common(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b388be",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"../data/processed/teachers_db_cleaned.parquet\"\n",
    "df.to_parquet(output_path, index=False)\n",
    "print(f\"Saved cleaned dataset to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a7c2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Build dictionaries per professor from sectioned entities ----\n",
    "def to_lists(section_entities):\n",
    "    orgs = [e[1] for e in section_entities if e[0] == \"ORG\"]\n",
    "    locs = [e[1] for e in section_entities if e[0] == \"LOC\"]\n",
    "    return orgs, locs\n",
    "\n",
    "def build_professor_dict_row(row):\n",
    "    corp_orgs, corp_locs = to_lists(row[\"norm_corp\"])\n",
    "    acadexp_orgs, acadexp_locs = to_lists(row[\"norm_acadexp\"])\n",
    "    acadbg_orgs, acadbg_locs = to_lists(row[\"norm_acadbg\"])\n",
    "\n",
    "    return {\n",
    "        \"Corporate Experience - Organization\": corp_orgs,\n",
    "        \"Corporate Experience - Location\": corp_locs,\n",
    "        \"Academic Background - Organization\": acadbg_orgs,\n",
    "        \"Academic Background - Education\": [],    # optional enhancement later (regex keywords)\n",
    "        \"Academic Experience - Courses\": [],      # optional\n",
    "        \"Academic Experience - Subjects\": [],     # optional\n",
    "        # You can also include acadexp_locs if you want:\n",
    "        # \"Academic Experience - Location\": acadexp_locs\n",
    "    }\n",
    "\n",
    "df[\"professor_dict\"] = df.apply(build_professor_dict_row, axis=1)\n",
    "\n",
    "# ---- Extract degrees/subjects from the \"Academic Background\" section and\n",
    "# move them out of ORGs into Academic Background - Education ----\n",
    "\n",
    "import re\n",
    "\n",
    "def get_section(text, start_key, stop_keys):\n",
    "    t = text or \"\"\n",
    "    t_low = t.lower()\n",
    "    s = t_low.find(start_key.lower())\n",
    "    if s == -1:\n",
    "        return \"\"\n",
    "    e_candidates = [t_low.find(k.lower(), s+1) for k in stop_keys]\n",
    "    e_candidates = [e for e in e_candidates if e != -1]\n",
    "    e = min(e_candidates) if e_candidates else len(t)\n",
    "    return t[s:e]\n",
    "\n",
    "# Broad degree / credential patterns (English + common ES terms)\n",
    "DEGREE_PAT = re.compile(\n",
    "    r\"\"\"\n",
    "    \\b(\n",
    "        ph\\.?d\\.?|doctor(?:ate)?\\s+of\\s+[A-Za-zÁÉÍÓÚÜÑ&\\-\\s]+|\n",
    "        m\\.?b\\.?a\\.?|m\\.?sc\\.?|m\\.?s\\.?|m\\.?a\\.?|ll\\.?m\\.?|\n",
    "        b\\.?sc\\.?|b\\.?s\\.?|b\\.?a\\.?|\n",
    "        master(?:'s)?\\s+in\\s+[A-Za-zÁÉÍÓÚÜÑ&\\-\\s]+|\n",
    "        bachelor(?:'s)?\\s+in\\s+[A-Za-zÁÉÍÓÚÜÑ&\\-\\s]+|\n",
    "        licenciatura\\s+en\\s+[A-Za-zÁÉÍÓÚÜÑ&\\-\\s]+|\n",
    "        grado\\s+en\\s+[A-Za-zÁÉÍÓÚÜÑ&\\-\\s]+\n",
    "    )\\b\n",
    "    \"\"\",\n",
    "    re.IGNORECASE | re.VERBOSE,\n",
    ")\n",
    "\n",
    "# Light subject extractor: “… in X” or “… of X”\n",
    "SUBJECT_PAT = re.compile(r\"\\b(?:in|of)\\s+([A-Z][A-Za-zÁÉÍÓÚÜÑ&\\-\\s]{3,})\")\n",
    "\n",
    "def split_background_fields(row):\n",
    "    # 1) Get the Academic Background text slice from your cleaned text\n",
    "    bg_text = get_section(\n",
    "        row.get(\"clean_text\", \"\"),\n",
    "        start_key=\"Academic Background\",\n",
    "        stop_keys=[\"Academic Experience\", \"Corporate Experience\"]\n",
    "    )\n",
    "\n",
    "    # 2) Degrees & subjects from the text\n",
    "    degrees = [m.group(0).strip().rstrip(\",.;\") for m in DEGREE_PAT.finditer(bg_text)]\n",
    "    subjects = [m.group(1).strip().rstrip(\",.;\") for m in SUBJECT_PAT.finditer(bg_text)]\n",
    "\n",
    "    # 3) Remove degree-like tokens that leaked into ORG buckets for this professor\n",
    "    d = row[\"professor_dict\"].copy()\n",
    "    ab_orgs = d.get(\"Academic Background - Organization\", [])\n",
    "    cleaned_ab_orgs = []\n",
    "    for org in ab_orgs:\n",
    "        if DEGREE_PAT.search(org) or SUBJECT_PAT.search(org):\n",
    "            continue\n",
    "        cleaned_ab_orgs.append(org)\n",
    "\n",
    "    # 4) Update dictionary\n",
    "    d[\"Academic Background - Organization\"] = cleaned_ab_orgs\n",
    "    d[\"Academic Background - Education\"] = sorted(set(d.get(\"Academic Background - Education\", []) + degrees))\n",
    "    # Optional: add subjects here (or keep for \"Academic Experience - Subjects\" later)\n",
    "    d[\"Academic Experience - Subjects\"] = sorted(set(d.get(\"Academic Experience - Subjects\", []) + subjects))\n",
    "\n",
    "    return d\n",
    "\n",
    "df[\"professor_dict\"] = df.apply(split_background_fields, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "56609aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Per-professor cleanup: dedupe, drop junk tokens, and light fallback ----\n",
    "import re\n",
    "\n",
    "JUNK_TOKENS = {\n",
    "    \"academic ba\", \"academic back\", \"of\", \"and\", \"school\", \"university\", \"ll. m\",\n",
    "    \"& am\", \"& amp\", \"research\", \"experience\", \"business\", \"administration\"\n",
    "}\n",
    "JUNK_RE = re.compile(r\"^(?:&|of|and|the|section|experience|academic|school|university)\\b\", re.I)\n",
    "\n",
    "def _clean_list(vals):\n",
    "    out = []\n",
    "    seen = set()\n",
    "    for v in vals:\n",
    "        v_norm = re.sub(r\"\\s+\", \" \", v).strip()\n",
    "        v_low = v_norm.lower()\n",
    "        if len(v_norm) < 3: \n",
    "            continue\n",
    "        if v_low in JUNK_TOKENS or JUNK_RE.match(v_norm):\n",
    "            continue\n",
    "        # fix common IE spacing (e.g., \"I E University\" -> \"IE\")\n",
    "        if v_norm.lower().replace(\" \", \"\") in {\"ieuniversity\", \"ie\"}:\n",
    "            v_norm = \"IE\"\n",
    "        if v_norm not in seen:\n",
    "            out.append(v_norm)\n",
    "            seen.add(v_norm)\n",
    "    return out\n",
    "\n",
    "def finalize_professor_dict(row):\n",
    "    d = row[\"professor_dict\"].copy()\n",
    "    # dedupe & clean\n",
    "    d[\"Corporate Experience - Organization\"] = _clean_list(d.get(\"Corporate Experience - Organization\", []))\n",
    "    d[\"Corporate Experience - Location\"]    = _clean_list(d.get(\"Corporate Experience - Location\", []))\n",
    "    d[\"Academic Background - Organization\"] = _clean_list(d.get(\"Academic Background - Organization\", []))\n",
    "    d[\"Academic Background - Education\"]    = _clean_list(d.get(\"Academic Background - Education\", []))\n",
    "    d[\"Academic Experience - Subjects\"]     = _clean_list(d.get(\"Academic Experience - Subjects\", []))\n",
    "    d[\"Academic Experience - Courses\"]      = _clean_list(d.get(\"Academic Experience - Courses\", []))\n",
    "\n",
    "    # fallback: if everything is empty, use raw NER buckets so graph isn't missing nodes\n",
    "    if not any(d[k] for k in d.keys()):\n",
    "        ents = row[\"normalized_entities\"]\n",
    "        d[\"Corporate Experience - Organization\"] = _clean_list([e[1] for e in ents if e[0]==\"ORG\"])\n",
    "        d[\"Corporate Experience - Location\"]    = _clean_list([e[1] for e in ents if e[0]==\"LOC\"])\n",
    "        d[\"Academic Background - Organization\"] = _clean_list([e[1] for e in ents if e[0]==\"ORG\"])\n",
    "\n",
    "    return d\n",
    "\n",
    "df[\"professor_dict\"] = df.apply(finalize_professor_dict, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365b7f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Re-bucket ORGs/LOCs by section using NER per section ----\n",
    "def section_entities(text, start_key, stop_keys, maxlen=2000):\n",
    "    s = get_section(text, start_key, stop_keys)\n",
    "    if not s:\n",
    "        return []\n",
    "    ents = ner(s[:maxlen])                 # reuse your loaded HF pipeline\n",
    "    return normalize_entities(ents)        # reuse your normalize_entities()\n",
    "\n",
    "def rebuild_from_sections(row):\n",
    "    d = row[\"professor_dict\"].copy()\n",
    "    txt = row.get(\"clean_text\", \"\")\n",
    "\n",
    "    corp_ents = section_entities(\n",
    "        txt, \"Corporate Experience\", [\"Academic Background\", \"Academic Experience\"]\n",
    "    )\n",
    "    acad_bg_ents = section_entities(\n",
    "        txt, \"Academic Background\", [\"Corporate Experience\", \"Academic Experience\"]\n",
    "    )\n",
    "\n",
    "    d[\"Corporate Experience - Organization\"] = sorted({n for t, n in corp_ents if t == \"ORG\"})\n",
    "    d[\"Corporate Experience - Location\"]     = sorted({n for t, n in corp_ents if t == \"LOC\"})\n",
    "    d[\"Academic Background - Organization\"]  = sorted({n for t, n in acad_bg_ents if t == \"ORG\"})\n",
    "    return d\n",
    "\n",
    "df[\"professor_dict\"] = df.apply(rebuild_from_sections, axis=1)\n",
    "\n",
    "# ---- Final small cleanup: drop headings/noise & de-dup ----\n",
    "import re\n",
    "JUNK_ORG = re.compile(\n",
    "    r\"^(academic( back| exp).*$|of excellence$|section \\d+(st|nd|rd|th)$|\"\n",
    "    r\"(journal|conference|school of|law school|business school)$|\"\n",
    "    r\"&\\s*am?p?$|watkins ll?$|ll\\.?$)\", re.IGNORECASE\n",
    ")\n",
    "PLACE_WORDS = {\"Spain\",\"Madrid\",\"Paris\",\"London\",\"Italy\",\"United States\",\"Europe\"}\n",
    "\n",
    "def clean_prof_dict(d):\n",
    "    def filt_org(lst):\n",
    "        out = []\n",
    "        for x in lst:\n",
    "            if len(x) < 3: continue\n",
    "            if JUNK_ORG.search(x): continue\n",
    "            out.append(x)\n",
    "        return sorted(set(out))\n",
    "\n",
    "    d[\"Corporate Experience - Organization\"] = filt_org(d.get(\"Corporate Experience - Organization\", []))\n",
    "    d[\"Academic Background - Organization\"]  = filt_org(d.get(\"Academic Background - Organization\", []))\n",
    "    d[\"Academic Experience - Subjects\"]      = [s for s in d.get(\"Academic Experience - Subjects\", []) if s not in PLACE_WORDS]\n",
    "    return d\n",
    "\n",
    "df[\"professor_dict\"] = df[\"professor_dict\"].apply(clean_prof_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "541d0cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Professor 1 ---\n",
      "Corporate Experience - Organization: ['Health Research And Innovation Policy Unit', 'Healthcare Innovation', 'Innovation And Infra', 'Regional Government Of Madrid']\n",
      "Corporate Experience - Location: []\n",
      "Academic Background - Organization: ['Universidad Autónoma De Madrid', 'Universidad Carlos', 'Universidad De Granada']\n",
      "Academic Background - Education: ['BSc', 'MSc', 'PhD']\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: []\n",
      "\n",
      "--- Professor 2 ---\n",
      "Corporate Experience - Organization: ['Rup London', 'Rup Madrid']\n",
      "Corporate Experience - Location: ['The Netherlands']\n",
      "Academic Background - Organization: ['Birmingham City Council', 'Perry Barr', 'Wellcome Genome Campus Masterp']\n",
      "Academic Background - Education: []\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: ['Valencia']\n",
      "\n",
      "--- Professor 3 ---\n",
      "Corporate Experience - Organization: []\n",
      "Corporate Experience - Location: []\n",
      "Academic Background - Organization: ['Cuela Técnica Superior De Arquitectura De Madrid', 'Facultad De Filosofía', 'La Técnica Superior De Arquitectura De Madrid']\n",
      "Academic Background - Education: ['PhD']\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: []\n",
      "\n",
      "--- Professor 4 ---\n",
      "Corporate Experience - Organization: ['A And Morgan Stanley', 'Advanced Analytics And Data', 'Bip Consulting', 'Newbers Energy Analytics']\n",
      "Corporate Experience - Location: ['London', 'Portugal', 'Spain']\n",
      "Academic Background - Organization: ['Academic Bac', 'Analistas Financieros Internacionales', 'Beta Gamma Sigma', 'Carlos Iii University', 'Iese Madrid', 'International Honor Society', 'Mathematical Engineering', 'Mplutense University Of Madrid']\n",
      "Academic Background - Education: ['M.B.A', 'Ph.D', 'PhD']\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: ['Business Management', 'Economics and Mathematical Engineering', 'Mathematical Engineering', 'Mathematics', 'Quantitative and Computational Finance', 'Structured Finance and Corporate Finance']\n",
      "\n",
      "--- Professor 5 ---\n",
      "Corporate Experience - Organization: []\n",
      "Corporate Experience - Location: []\n",
      "Academic Background - Organization: ['Ghent University']\n",
      "Academic Background - Education: ['Ph.D']\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: ['Psychology']\n",
      "\n",
      "--- Professor 6 ---\n",
      "Corporate Experience - Organization: ['Careers Management Center', 'Time Programs']\n",
      "Corporate Experience - Location: ['Entre']\n",
      "Academic Background - Organization: ['International Coach Federation', 'R Management', 'Universidad De Oviedo']\n",
      "Academic Background - Education: ['Bachelor in Economics', 'MBA', 'Master in HR Management']\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: ['Economics', 'HR Management']\n",
      "\n",
      "--- Professor 7 ---\n",
      "Corporate Experience - Organization: ['Airbus Defense And Space S', 'Airbus Operations Gmbh', 'Consumer Electronics', 'Data Science', 'Flight Physics', 'H. I. G', 'Mckinsey & Am', 'Structural Dynamics And Aeroelasticity']\n",
      "Corporate Experience - Location: ['Amazon', 'Colombia', 'Germany', 'Hamburg', 'Madrid', 'México', 'Novartis', 'Spain']\n",
      "Academic Background - Organization: ['Aerospace Engineering', 'Aircraft And Space Vehicles']\n",
      "Academic Background - Education: []\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: ['Aerospace Engineering', 'Aircraft and Space Vehicles', 'Business Administration', 'Finance and Economics']\n",
      "\n",
      "--- Professor 8 ---\n",
      "Corporate Experience - Organization: ['Economics Consulting Group', 'Global Competition Group', 'Global Policy Law & Amp', 'International Center For Law & Amp', 'Latham & Am', 'Law & Amp', 'Microsoft Corporation', 'Watkins Llp']\n",
      "Corporate Experience - Location: ['Portland', 'Redmond', 'United States', 'Washington']\n",
      "Academic Background - Organization: ['University Of Chicago']\n",
      "Academic Background - Education: []\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: ['Chicago']\n",
      "\n",
      "--- Professor 9 ---\n",
      "Corporate Experience - Organization: ['Mum Data']\n",
      "Corporate Experience - Location: ['Grifols', 'Psos', 'Spain']\n",
      "Academic Background - Organization: ['Data Literacy', 'Information And Knowledge Society', 'La Salle Url']\n",
      "Academic Background - Education: ['PhD']\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: ['Data Literacy']\n",
      "\n",
      "--- Professor 10 ---\n",
      "Corporate Experience - Organization: ['Arcano Partners', 'Business Administration', 'Equity Research', 'Equity Research Ana', 'Financial Division', 'Fénix Networks Acamic Experience', 'Knights Tempr', 'Madrid Bar Association', 'North American Case Research Association', 'The Phoenix', 'Tsche Bank', 'Ubs Investment Bank', 'Universidad Nacional Eduación A Distancia', 'Universidad Nacional Educación', 'Universidad Pontificia Comillas']\n",
      "Corporate Experience - Location: ['Fontainebleau', 'France', 'Miami', 'Singapore', 'Spain']\n",
      "Academic Background - Organization: []\n",
      "Academic Background - Education: []\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: []\n",
      "\n",
      "--- Professor 11 ---\n",
      "Corporate Experience - Organization: ['Mesa Design Group', 'Urban Planning']\n",
      "Corporate Experience - Location: ['Sala', 'Spain']\n",
      "Academic Background - Organization: ['Universidad Complutense de Madrid', 'Universidad Politécnica De Madrid']\n",
      "Academic Background - Education: ['MSc', 'Ph.D']\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: ['Architecture', 'Environmental Studies', 'Geography']\n",
      "\n",
      "--- Professor 12 ---\n",
      "Corporate Experience - Organization: []\n",
      "Corporate Experience - Location: []\n",
      "Academic Background - Organization: ['Complutense University', 'Media Business School', 'New Media', 'The School Of The Art Institute Of Chicago', 'Waseda University Tokyo']\n",
      "Academic Background - Education: ['Master in Audiovisual Management']\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: ['Audiovisual Management', 'Chicago', 'Fine Arts']\n",
      "\n",
      "--- Professor 13 ---\n",
      "Corporate Experience - Organization: ['Student Enterprise', 'Universidade Federal Do Rio Grande Do', 'Universidade Federal Do Rio Grande Do Sul']\n",
      "Corporate Experience - Location: ['Brazil', 'Sul']\n",
      "Academic Background - Organization: ['Universidade Federal Do Rio Grande Do', 'Universidade Federal Do Rio Grande Do Sul']\n",
      "Academic Background - Education: ['MSc', 'PhD']\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: ['Business Administration', 'Management', 'Marketing']\n",
      "\n",
      "--- Professor 14 ---\n",
      "Corporate Experience - Organization: ['Aboriginal Affairs And Northern Development Canada', 'Canadian Association Of Alternatives In Therapy', 'Institute For The Study Of The Crimes Of Communism', 'Museum Of Sciences And Technology', 'Social Sciences And Humanities Research Council Of Canada', 'The Memory Of The Romanian Exile']\n",
      "Corporate Experience - Location: ['Bucharest', 'Canada', 'Ottawa', 'Romania']\n",
      "Academic Background - Organization: ['Academic Bac', 'Agence Universitaire De La Francophonie', 'University Of Bucharest', 'University Of Laval']\n",
      "Academic Background - Education: ['Master in Social Sciences', 'PhD']\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: ['Bucharest', 'History', 'Laval', 'Social Sciences']\n",
      "\n",
      "--- Professor 15 ---\n",
      "Corporate Experience - Organization: ['And Environment', 'International Trade Office', 'Transfer Office']\n",
      "Corporate Experience - Location: ['Spain']\n",
      "Academic Background - Organization: ['Universidad Carlos', 'University Of Toronto']\n",
      "Academic Background - Education: ['Bachelor in Business Administration', 'Bachelor in Economics', 'LLM']\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: ['Business Administration', 'Economics', 'Laws', 'Toronto']\n",
      "\n",
      "--- Professor 16 ---\n",
      "Corporate Experience - Organization: []\n",
      "Corporate Experience - Location: []\n",
      "Academic Background - Organization: ['Business Sciences', 'Finance Department', 'Financial And Control Management', 'Financial Management', 'Harvard University', 'Individual Studies Program Graduate Business School', 'Instituto De Estudios Superiores De La Empresa', 'Management Control', 'O Digsa', 'O Isolux', 'Sarrio Tisú', 'Universidad Autónoma De Madrid', 'Universidad De Barcelona', 'Universidad de Navarra']\n",
      "Academic Background - Education: ['MBA', 'Master in Financial and Control Management', 'PhD']\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: ['Economic Theory', 'Economics &amp', 'Financial Management', 'Financial and Control Management', 'Management Control', 'Sarrio Tis']\n",
      "\n",
      "--- Professor 17 ---\n",
      "Corporate Experience - Organization: ['Compliance Department', 'Corporate And Commercial Law Department', 'Corporate Law Department', 'Deloitte Asesores Tributarios Slu', 'Ernst & Amp', 'Ing Spain']\n",
      "Corporate Experience - Location: ['Garrigues', 'Portugal', 'Spain', 'Young']\n",
      "Academic Background - Organization: ['And Finance', 'Centro De Estudios Financieros', 'Centro De Estudios Gar', 'Mcgeorge School Of Law', 'Salzburg University', 'University Of The Pacific', 'University Of Zaragoza']\n",
      "Academic Background - Education: ['LLM', 'Master in Banking and Finance']\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: ['Banking and Finance', 'Law', 'Zaragoza']\n",
      "\n",
      "--- Professor 18 ---\n",
      "Corporate Experience - Organization: ['Abu Dhabi Distribution Company', 'Africa Development Bank', 'At & Amp', 'Moving Forward', 'United Nations', 'World Knowledge Forum']\n",
      "Corporate Experience - Location: ['Asia', 'Europe', 'Middle East', 'United States']\n",
      "Academic Background - Organization: ['Clark University', 'Harvard University', 'Social Psychology', 'State University Of New York At', 'Universidad Autónoma De Madrid']\n",
      "Academic Background - Education: ['Master in Cognitive', 'PhD']\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: ['Cognitive', 'New York at Buffalo', 'Psychology Applied to Business', 'Psychology and Management Science', 'Science in Psychology']\n",
      "\n",
      "--- Professor 19 ---\n",
      "Corporate Experience - Organization: ['O Labs', 'Reto Emprende']\n",
      "Corporate Experience - Location: ['Joband', 'Spain', 'United States']\n",
      "Academic Background - Organization: ['Academic Ba', 'And Business', 'Massachusetts Institute Of Technology', 'Rey Juan Carlos University']\n",
      "Academic Background - Education: ['MBA']\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: ['Business Administration', 'Computer Science and Business Administration', 'Technology']\n",
      "\n",
      "--- Professor 20 ---\n",
      "Corporate Experience - Organization: []\n",
      "Corporate Experience - Location: []\n",
      "Academic Background - Organization: []\n",
      "Academic Background - Education: []\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: []\n",
      "\n",
      "--- Professor 21 ---\n",
      "Corporate Experience - Organization: []\n",
      "Corporate Experience - Location: []\n",
      "Academic Background - Organization: []\n",
      "Academic Background - Education: []\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: []\n",
      "\n",
      "--- Professor 22 ---\n",
      "Corporate Experience - Organization: []\n",
      "Corporate Experience - Location: []\n",
      "Academic Background - Organization: ['Autonomous University Of Madrid', 'Democracy And Government', 'European University Institute', 'Hacettepe University', 'Sabanci University', 'University Of Mannheim', 'Vienna University Of Economics And Business Administration']\n",
      "Academic Background - Education: ['PhD']\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: ['Democracy and Government', 'Economics', 'Economics and Business Administration', 'Europe in Times of Crisis', 'Law and Political Science', 'Mannheim']\n",
      "\n",
      "--- Professor 23 ---\n",
      "Corporate Experience - Organization: ['Economy And Competitiveness', 'European Investment Bank', 'Financial Policy', 'Iberdrola España', 'Instituto De Crédito Oficial', 'Long Term Investors Club', 'Ministry Of Economy And Competitiveness']\n",
      "Corporate Experience - Location: ['Colombia', 'Luxembourg', 'Mexico', 'Spain', 'Venezuela']\n",
      "Academic Background - Organization: ['Civil Servant Corps', 'Complutense University Of Madrid', 'Paris I Panthéon', 'Sorbonne University', 'Trade Ex', 'Universidad San Pablo Ceu']\n",
      "Academic Background - Education: []\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: ['EU Law', 'EU legal and economic studies from Paris I Panth']\n",
      "\n",
      "--- Professor 24 ---\n",
      "Corporate Experience - Organization: ['Armesto & Am', 'Asociados Árbitros', 'International Arb', 'International Dispute Resolution', 'Madrid International Arbitration Center']\n",
      "Corporate Experience - Location: ['Madrid']\n",
      "Academic Background - Organization: []\n",
      "Academic Background - Education: []\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: []\n",
      "\n",
      "--- Professor 25 ---\n",
      "Corporate Experience - Organization: ['Ernst & Amp', 'Tetra Pak']\n",
      "Corporate Experience - Location: []\n",
      "Academic Background - Organization: ['Engineering And Management', 'Iversitá Di Padova']\n",
      "Academic Background - Education: ['PhD']\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: ['Engineering and Management', 'Operations Management']\n",
      "\n",
      "--- Professor 26 ---\n",
      "Corporate Experience - Organization: ['Ashton Tate Borland', 'Capgemini Ernst & Am', 'Capgemini Ernst & Amp', 'Enterprise & Am']\n",
      "Corporate Experience - Location: []\n",
      "Academic Background - Organization: ['Krauthammer International', 'Universidad Complutense Madrid', 'Universidad De California', 'Universidad Politécnica Madrid']\n",
      "Academic Background - Education: ['Master in Business Administration', 'Master in Software Architecture']\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: ['Business Administration', 'Computer', 'Marketing', 'Quality Management', 'Software Architecture']\n",
      "\n",
      "--- Professor 27 ---\n",
      "Corporate Experience - Organization: []\n",
      "Corporate Experience - Location: []\n",
      "Academic Background - Organization: ['Autonomous University Of Madrid', 'Cells And Hydrogen', 'Complutense University Of Madrid', 'Environmental Sciences', 'Menéndez Pelayo International University Uimp', 'Renewable Energy', 'Universidad Autónoma de Madrid']\n",
      "Academic Background - Education: ['Bachelor in Environmental Sciences', 'Ph.D', 'PhD']\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: ['Environmental Sciences', 'Microbiology', 'Pedagogic Aptitude', 'Renewable Energy']\n",
      "\n",
      "--- Professor 28 ---\n",
      "Corporate Experience - Organization: ['Construction Kaiser Limited', 'Copperbelt Energy Corporation Plc', 'Detail Commercial Solicitors', 'Ebola Containment Trust Fund', 'Founders Carbon Network', 'Gmh Luxury', 'Intellifin Solutions Limited', 'Minting Company', 'Nigerian Alumni Association', 'Nigerian Bar Association', 'Nigerian Security Printing & Amp', 'Real Estate Developers', 'Swiss Chamber Of Commerce', 'The Online Publishers Limited', 'West African Glass Industry Plc']\n",
      "Corporate Experience - Location: ['Delaware', 'Lagos Nigeria', 'Nigeria', 'United States']\n",
      "Academic Background - Organization: ['Chartered Institute Of Arbitrators', 'Columbia Business School', 'Institute For Public Private Partnerships', 'Nigerian Bar Association', 'Northwestern University', 'Of Pennsylvania', 'University Of Benin', 'Wharton Business School']\n",
      "Academic Background - Education: ['LLM']\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: ['Arbitrators', 'Benin', 'Business Administration', 'Pennsylvania']\n",
      "\n",
      "--- Professor 29 ---\n",
      "Corporate Experience - Organization: ['Altran Group', 'Daemon Quest', 'Deloitte Digital', 'Frog Design', 'Innovation Practice']\n",
      "Corporate Experience - Location: ['Elux', 'Spain']\n",
      "Academic Background - Organization: ['Harvard Business School', 'M University', 'Texas A & Am', 'Universidad Autónoma De Madrid']\n",
      "Academic Background - Education: ['PhD']\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: ['Chemistry']\n",
      "\n",
      "--- Professor 30 ---\n",
      "Corporate Experience - Organization: ['Apple Retail Emeia', 'Loewy Group', 'Six Limited', 'Uk Nike Team']\n",
      "Corporate Experience - Location: []\n",
      "Academic Background - Organization: ['Middlesex University', 'Pma Training']\n",
      "Academic Background - Education: []\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import random\n",
    "for i, d in enumerate(df[\"professor_dict\"].sample(30, random_state=43).to_list(), 1):\n",
    "    print(f\"\\n--- Professor {i} ---\")\n",
    "    for k, v in d.items():\n",
    "        print(f\"{k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e67e08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Save cleaned data for Notebook 2 ----\n",
    "import json\n",
    "\n",
    "# Save as JSON\n",
    "output_path = \"data/cleaned_professors.json\"\n",
    "df[[\"clean_text\", \"professor_dict\"]].to_json(output_path, orient=\"records\", indent=2, force_ascii=False)\n",
    "\n",
    "print(f\"Saved cleaned dataset to {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

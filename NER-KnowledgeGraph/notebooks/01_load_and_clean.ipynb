{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c6360f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"../data/raw/teachers_db_practice.csv\")\n",
    "\n",
    "# Take a quick look\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4d2b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "print(df.loc[0, \"full_info\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ee9c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Remove HTML tags and extra whitespace\n",
    "df[\"clean_text\"] = (\n",
    "    df[\"full_info\"]\n",
    "    .fillna(\"\")\n",
    "    .apply(lambda x: re.sub(r\"<.*?>\", \" \", x))\n",
    "    .apply(lambda x: re.sub(r\"\\s+\", \" \", x).strip())\n",
    ")\n",
    "\n",
    "df[\"clean_text\"].head(3).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11396d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Extract sections from the original HTML-ish text ----\n",
    "import re\n",
    "\n",
    "SECTION_HEADERS = {\n",
    "    \"corp\": r\"(?:<h4>\\s*CORPORATE EXPERIENCE\\s*</h4>|CORPORATE EXPERIENCE)\",\n",
    "    \"acadexp\": r\"(?:<h4>\\s*ACADEMIC EXPERIENCE\\s*</h4>|ACADEMIC EXPERIENCE)\",\n",
    "    \"acadbg\": r\"(?:<h4>\\s*ACADEMIC BACKGROUND\\s*</h4>|ACADEMIC BACKGROUND)\",\n",
    "}\n",
    "\n",
    "def strip_html(s: str) -> str:\n",
    "    if not isinstance(s, str):\n",
    "        return \"\"\n",
    "    # fix common &amp; noise then strip tags\n",
    "    s = re.sub(r\"&\\s*amp;?\", \"&\", s, flags=re.I)\n",
    "    s = re.sub(r\"<.*?>\", \" \", s)              # remove tags\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def extract_sections(raw: str):\n",
    "    text = raw if isinstance(raw, str) else \"\"\n",
    "    # Normalize case for header matching but keep original for content slicing\n",
    "    low = text.lower()\n",
    "\n",
    "    def find_idx(pattern):\n",
    "        m = re.search(pattern, text, flags=re.I)\n",
    "        return m.start() if m else None\n",
    "\n",
    "    i_corp = find_idx(SECTION_HEADERS[\"corp\"])\n",
    "    i_acadexp = find_idx(SECTION_HEADERS[\"acadexp\"])\n",
    "    i_acadbg = find_idx(SECTION_HEADERS[\"acadbg\"])\n",
    "\n",
    "    # helper to slice safely\n",
    "    def slice_between(start, end):\n",
    "        if start is None:\n",
    "            return \"\"\n",
    "        end = len(text) if end is None else end\n",
    "        return strip_html(text[start:end])\n",
    "\n",
    "    # determine boundaries\n",
    "    idxs = sorted([(k, v) for k, v in [(\"corp\", i_corp), (\"acadexp\", i_acadexp), (\"acadbg\", i_acadbg)] if v is not None],\n",
    "                  key=lambda x: x[1])\n",
    "    corp_txt = acadexp_txt = acadbg_txt = \"\"\n",
    "    if idxs:\n",
    "        # walk through in order and slice to next header\n",
    "        for j, (label, start) in enumerate(idxs):\n",
    "            end = idxs[j+1][1] if j+1 < len(idxs) else None\n",
    "            chunk = slice_between(start, end)\n",
    "            if label == \"corp\": corp_txt = chunk\n",
    "            elif label == \"acadexp\": acadexp_txt = chunk\n",
    "            elif label == \"acadbg\": acadbg_txt = chunk\n",
    "    else:\n",
    "        # fallback: no headers -> treat all as one generic blob (will still be used if needed)\n",
    "        corp_txt = strip_html(text)\n",
    "\n",
    "    return pd.Series({\n",
    "        \"corp_text\": corp_txt,\n",
    "        \"acadexp_text\": acadexp_txt,\n",
    "        \"acadbg_text\": acadbg_txt\n",
    "    })\n",
    "\n",
    "sec_df = df[\"full_info\"].apply(extract_sections)\n",
    "df = pd.concat([df, sec_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b3db90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load a pre-trained NER model\n",
    "ner = pipeline(\"ner\", model=\"dslim/bert-base-NER\", aggregation_strategy=\"simple\")\n",
    "\n",
    "# Test on small sample of dataset\n",
    "sample_text = df.loc[1, \"clean_text\"]\n",
    "ner_results = ner(sample_text[:1000])  # limit to 1000 chars just to test\n",
    "ner_results[:10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be12dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "df[\"entities\"] = df[\"clean_text\"].progress_apply(lambda x: ner(x[:2000]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c2a694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Run NER per section (safer for dict building) ----\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "def run_ner_safe(s, limit=2000):\n",
    "    s = s if isinstance(s, str) else \"\"\n",
    "    return ner(s[:limit]) if s else []\n",
    "\n",
    "df[\"entities_corp\"]    = df[\"corp_text\"].progress_apply(run_ner_safe)\n",
    "df[\"entities_acadexp\"] = df[\"acadexp_text\"].progress_apply(run_ner_safe)\n",
    "df[\"entities_acadbg\"]  = df[\"acadbg_text\"].progress_apply(run_ner_safe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f444ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "def normalize_entities(entities):\n",
    "    cleaned = []\n",
    "    for ent in entities:\n",
    "        word = ent[\"word\"].strip()\n",
    "        # Remove stray punctuation and unify case\n",
    "        word = word.replace(\".\", \"\").replace(\",\", \"\").title()\n",
    "        cleaned.append((ent[\"entity_group\"], word))\n",
    "    return cleaned\n",
    "\n",
    "df[\"normalized_entities\"] = df[\"entities\"].apply(normalize_entities)\n",
    "df[\"normalized_entities\"].head(2).values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c2574c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acb83ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "LOCATION_MAP = {\n",
    "    \"us\": \"United States\",\n",
    "    \"usa\": \"United States\",\n",
    "    \"u.s.\": \"United States\",\n",
    "    \"u.k.\": \"United Kingdom\",\n",
    "    \"uk\": \"United Kingdom\",\n",
    "    \"spain\": \"Spain\",\n",
    "    \"madrid\": \"Madrid\",\n",
    "    \"mexico\": \"Mexico\",\n",
    "    \"mexico city\": \"Mexico City\",\n",
    "    \"london\": \"London\",\n",
    "    \"paris\": \"Paris\",\n",
    "    \"france\": \"France\",\n",
    "    \"germany\": \"Germany\",\n",
    "    \"italy\": \"Italy\",\n",
    "    \"portugal\": \"Portugal\",\n",
    "    \"barcelona\": \"Barcelona\",\n",
    "    \"new york\": \"New York\",\n",
    "}\n",
    "\n",
    "ORG_FIXES = {\n",
    "    # IE ecosystem\n",
    "    \"ie\": \"IE\",\n",
    "    \"ie university\": \"IE\",\n",
    "    \"ie business school\": \"IE\",\n",
    "    \"ie law school\": \"IE\",\n",
    "    \"instituto de empresa\": \"IE\",\n",
    "    \"ie school of global and public affairs\": \"IE\",\n",
    "    # Spanish universities\n",
    "    \"universidad autonoma de madrid\": \"Universidad Autónoma de Madrid\",\n",
    "    \"uam\": \"Universidad Autónoma de Madrid\",\n",
    "    \"universidad complutense de madrid\": \"Universidad Complutense de Madrid\",\n",
    "    \"universidad carlos iii de madrid\": \"Universidad Carlos III de Madrid\",\n",
    "    \"universidad politecnica de madrid\": \"Universidad Politécnica de Madrid\",\n",
    "    \"universidad de navarra\": \"Universidad de Navarra\",\n",
    "    \"universidad pontificia comillas\": \"Universidad Pontificia Comillas\",\n",
    "    \"comillas university\": \"Universidad Pontificia Comillas\",\n",
    "    \"icade\": \"Universidad Pontificia Comillas\",\n",
    "    \"iese business school\": \"IESE Business School\",\n",
    "    # companies / misc\n",
    "    \"a & am\": \"A&M Studio\",\n",
    "    \"a&m\": \"A&M Studio\",\n",
    "    \"am studio\": \"A&M Studio\",\n",
    "}\n",
    "\n",
    "GENERIC_ORG_WORDS = {\n",
    "    \"academic\", \"academic exp\", \"academ\", \"experience\", \"exp\",\n",
    "    \"university\", \"universidad\", \"engineering\", \"design\",\n",
    "    \"academy\", \"school\", \"faculty\", \"department\", \"college\",\n",
    "    \"education\", \"institute\", \"business\", \"finance\", \"management\",\n",
    "    \"administration\", \"economics\", \"marketing\", \"law\", \"science\",\n",
    "    \"technology\", \"research\", \"professor\", \"lecturer\"\n",
    "}\n",
    "\n",
    "def normalize_entities(entities):\n",
    "    cleaned = []\n",
    "    for ent in entities:\n",
    "        text = ent[\"word\"].lower().strip()\n",
    "        text = re.sub(r\"[^a-z0-9&.\\sáéíóúüñ]\", \"\", text)\n",
    "        text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "        if len(text) < 3:\n",
    "            continue\n",
    "\n",
    "        if ent[\"entity_group\"] == \"LOC\":\n",
    "            text = LOCATION_MAP.get(text, text.title())\n",
    "\n",
    "        elif ent[\"entity_group\"] == \"ORG\":\n",
    "            text = ORG_FIXES.get(text, text.title())\n",
    "\n",
    "            # drop headings and generic garbage\n",
    "            if (\n",
    "                text.lower() in GENERIC_ORG_WORDS\n",
    "                or len(text.split()) == 1 and text.lower() not in [v.lower() for v in ORG_FIXES.values()]\n",
    "            ):\n",
    "                continue\n",
    "\n",
    "        else:\n",
    "            text = text.title()\n",
    "\n",
    "        cleaned.append((ent[\"entity_group\"], text))\n",
    "    return cleaned\n",
    "\n",
    "df[\"normalized_entities\"] = df[\"entities\"].apply(normalize_entities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287f153e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Normalize per section ----\n",
    "df[\"norm_corp\"]    = df[\"entities_corp\"].apply(normalize_entities)\n",
    "df[\"norm_acadexp\"] = df[\"entities_acadexp\"].apply(normalize_entities)\n",
    "df[\"norm_acadbg\"]  = df[\"entities_acadbg\"].apply(normalize_entities)\n",
    "\n",
    "# Optional: fuzzy consolidate inside each section\n",
    "df = consolidate_similar_entities(df, \"ORG\", threshold=90)  # keeps df[\"normalized_entities\"], but we’ll use the sectioned cols\n",
    "# (If you want the consolidate step section-specific, you can skip it here; your maps already did most of the work.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b71db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- SECTION-AWARE EXTRACTION (place directly under the last normalized_entities assignment) --------\n",
    "import re\n",
    "from html import unescape\n",
    "\n",
    "def _extract_section(html_text, header):\n",
    "    \"\"\"Grab text under <h4>HEADER</h4> until the next <h4> or end.\"\"\"\n",
    "    if not isinstance(html_text, str):\n",
    "        return \"\"\n",
    "    s = unescape(html_text)  # fixes '&amp;' -> '&' so we don't get '& Am'\n",
    "    # capture everything after this header up to next <h4> or end\n",
    "    m = re.search(rf\"<h4>\\s*{header}\\s*</h4>(.*?)(?=<h4>|$)\", s, flags=re.I|re.S)\n",
    "    if not m:\n",
    "        return \"\"\n",
    "    # strip tags but keep text\n",
    "    body = re.sub(r\"<.*?>\", \" \", m.group(1))\n",
    "    body = re.sub(r\"\\s+\", \" \", body).strip()\n",
    "    return body\n",
    "\n",
    "# 1) Parse sections from the original HTML (not the stripped text)\n",
    "df[\"section_corporate\"] = df[\"full_info\"].apply(lambda x: _extract_section(x, \"CORPORATE EXPERIENCE\"))\n",
    "df[\"section_acad_exp\"]  = df[\"full_info\"].apply(lambda x: _extract_section(x, \"ACADEMIC EXPERIENCE\"))\n",
    "df[\"section_acad_bg\"]   = df[\"full_info\"].apply(lambda x: _extract_section(x, \"ACADEMIC BACKGROUND\"))\n",
    "\n",
    "# 2) Run NER per section (short-circuit empty strings; limit length to be laptop-friendly)\n",
    "def _safe_ner(txt):\n",
    "    if not txt:\n",
    "        return []\n",
    "    return ner(txt[:2000])  # reuse your existing HF pipeline\n",
    "\n",
    "df[\"corp_entities\"] = df[\"section_corporate\"].apply(_safe_ner)\n",
    "df[\"acadexp_entities\"] = df[\"section_acad_exp\"].apply(_safe_ner)\n",
    "df[\"acadbg_entities\"] = df[\"section_acad_bg\"].apply(_safe_ner)\n",
    "\n",
    "# 3) Reuse your normalization on each section\n",
    "df[\"corp_norm\"]    = df[\"corp_entities\"].apply(normalize_entities)\n",
    "df[\"acadexp_norm\"] = df[\"acadexp_entities\"].apply(normalize_entities)\n",
    "df[\"acadbg_norm\"]  = df[\"acadbg_entities\"].apply(normalize_entities)\n",
    "\n",
    "# 4) Build the assignment-style dictionary PER PROFESSOR using sectioned entities\n",
    "def _pick(ents, label): \n",
    "    return [e[1] for e in ents if e[0] == label]\n",
    "\n",
    "def build_professor_dict_from_sections(row):\n",
    "    corp, aexp, abg = row[\"corp_norm\"], row[\"acadexp_norm\"], row[\"acadbg_norm\"]\n",
    "    return {\n",
    "        \"Corporate Experience - Organization\": _pick(corp, \"ORG\"),\n",
    "        \"Corporate Experience - Location\":     _pick(corp, \"LOC\"),\n",
    "        \"Academic Background - Organization\":  _pick(abg,  \"ORG\"),\n",
    "        \"Academic Background - Education\":     [],   # optional: fill later with regex/keywords\n",
    "        \"Academic Experience - Courses\":       [],   # optional\n",
    "        \"Academic Experience - Subjects\":      []    # optional\n",
    "    }\n",
    "\n",
    "df[\"professor_dict\"] = df.apply(build_professor_dict_from_sections, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3c9d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Auto-alias clustering for ORG/LOC without hardcoding ---\n",
    "\n",
    "import unicodedata\n",
    "from collections import Counter, defaultdict\n",
    "from rapidfuzz import fuzz, process\n",
    "\n",
    "def simplify_for_match(s: str) -> str:\n",
    "    # lowercase, strip accents, remove stop words like university/universidad/etc., collapse spaces\n",
    "    s0 = s.lower().strip()\n",
    "    s0 = \"\".join(c for c in unicodedata.normalize(\"NFKD\", s0) if not unicodedata.combining(c))\n",
    "    s0 = s0.replace(\"&\", \"and\")\n",
    "    # drop very generic words in many languages\n",
    "    drop = {\"university\",\"universidad\",\"universite\",\"università\",\"universita\",\"universidade\",\n",
    "            \"school\",\"college\",\"institute\",\"instituto\",\"universidad\",\"dept\",\"department\"}\n",
    "    tokens = [t for t in re.sub(r\"[^a-z0-9\\s]\", \" \", s0).split() if t not in drop]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# collect all ORG/LOC surface forms\n",
    "all_orgs = []\n",
    "all_locs = []\n",
    "for row in df[\"normalized_entities\"]:\n",
    "    for typ, val in row:\n",
    "        if typ == \"ORG\":\n",
    "            all_orgs.append(val)\n",
    "        elif typ == \"LOC\":\n",
    "            all_locs.append(val)\n",
    "\n",
    "def build_alias_map(names, sim_threshold=92):\n",
    "    names = list(set(names))\n",
    "    # group by simplified key first (fast win)\n",
    "    buckets = defaultdict(list)\n",
    "    for n in names:\n",
    "        buckets[simplify_for_match(n)].append(n)\n",
    "\n",
    "    alias_map = {}\n",
    "\n",
    "    # within each bucket, pick the most common as canonical; also fuzzy-merge near buckets\n",
    "    # pick canonical = most frequent original form\n",
    "    freq = Counter(names)\n",
    "\n",
    "    # first pass: intra-bucket\n",
    "    for _, variants in buckets.items():\n",
    "        canonical = max(variants, key=lambda x: freq[x])\n",
    "        for v in variants:\n",
    "            alias_map[v] = canonical\n",
    "\n",
    "    # second pass: inter-bucket fuzzy consolidation of canonicals\n",
    "    canonicals = list(set(alias_map[v] for v in alias_map))\n",
    "    for c in canonicals:\n",
    "        # find nearest other canonicals by token_sort_ratio\n",
    "        matches = process.extract(c, canonicals, scorer=fuzz.token_sort_ratio, limit=5)\n",
    "        for other, score, _ in matches:\n",
    "            if other != c and score >= sim_threshold:\n",
    "                # unify to the most frequent of the two\n",
    "                winner = c if freq[c] >= freq[other] else other\n",
    "                loser  = other if winner == c else c\n",
    "                # redirect all aliases pointing to loser → winner\n",
    "                for k, v in list(alias_map.items()):\n",
    "                    if v == loser:\n",
    "                        alias_map[k] = winner\n",
    "                # also update the canonical list\n",
    "                canonicals = [winner if x == loser else x for x in canonicals]\n",
    "\n",
    "    return alias_map\n",
    "\n",
    "ORG_ALIAS = build_alias_map(all_orgs, sim_threshold=92)\n",
    "LOC_ALIAS = build_alias_map(all_locs, sim_threshold=95)\n",
    "\n",
    "def apply_aliases(entities):\n",
    "    out = []\n",
    "    for typ, val in entities:\n",
    "        if typ == \"ORG\":\n",
    "            out.append((typ, ORG_ALIAS.get(val, val)))\n",
    "        elif typ == \"LOC\":\n",
    "            out.append((typ, LOC_ALIAS.get(val, val)))\n",
    "        else:\n",
    "            out.append((typ, val))\n",
    "    return out\n",
    "\n",
    "df[\"normalized_entities\"] = df[\"normalized_entities\"].apply(apply_aliases)\n",
    "\n",
    "# --- Build per-professor property dictionaries based on sections ---\n",
    "\n",
    "SECTION_KEYS = {\n",
    "    \"corporate\": [\"<h4>corporate experience</h4>\", \"corporate experience\"],\n",
    "    \"academic_exp\": [\"<h4>academic experience</h4>\", \"academic experience\"],\n",
    "    \"academic_bg\": [\"<h4>academic background</h4>\", \"academic background\"],\n",
    "}\n",
    "\n",
    "DEGREE_PAT = re.compile(\n",
    "    r\"\\b(ph\\.?d|doctorate|msc|m\\.sc\\.|ms|ma|m\\.a\\.|mba|bsc|b\\.sc\\.|bs|ba|b\\.a\\.|llm|jd|md)\\b\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "# light list of subjects to catch common terms (extend later if you want)\n",
    "SUBJECT_PAT = re.compile(\n",
    "    r\"\\b(machine learning|quantum physics|mathematics|finance|economics|marketing|law|computer science|data science)\\b\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "def get_sections(raw_html_or_text:str):\n",
    "    \"\"\"Return dict with text per section; robust to having tags removed or present.\"\"\"\n",
    "    t = raw_html_or_text or \"\"\n",
    "    t_l = t.lower()\n",
    "    # find start indices\n",
    "    idx = {}\n",
    "    for key, variants in SECTION_KEYS.items():\n",
    "        for v in variants:\n",
    "            p = t_l.find(v)\n",
    "            if p != -1:\n",
    "                idx[key] = p\n",
    "                break\n",
    "    # slice text by nearest next section\n",
    "    order = [k for k in [\"corporate\",\"academic_exp\",\"academic_bg\"] if k in idx]\n",
    "    out = {\"corporate\":\"\", \"academic_exp\":\"\", \"academic_bg\":\"\"}\n",
    "    for i,k in enumerate(order):\n",
    "        start = idx[k]\n",
    "        end = idx[order[i+1]] if i+1 < len(order) else len(t)\n",
    "        out[k] = re.sub(r\"<.*?>\",\" \", t[start:end])  # strip tags inside slice\n",
    "    # fallback: if nothing matched, put everything in academic_exp to not lose info\n",
    "    if not any(out.values()):\n",
    "        out[\"academic_exp\"] = re.sub(r\"<.*?>\",\" \", t)\n",
    "    # compact whitespace\n",
    "    for k in out:\n",
    "        out[k] = re.sub(r\"\\s+\",\" \", out[k]).strip()\n",
    "    return out\n",
    "\n",
    "def build_property_dict(row):\n",
    "    sections = get_sections(row.get(\"full_info\",\"\") or row.get(\"clean_text\",\"\"))\n",
    "    ents = row[\"normalized_entities\"]\n",
    "\n",
    "    def pick_in(section_text, typ):\n",
    "        hits = []\n",
    "        S = section_text.lower()\n",
    "        for t, val in ents:\n",
    "            if t != typ: \n",
    "                continue\n",
    "            v = val.lower()\n",
    "            # string containment as a simple attribution heuristic\n",
    "            if v and v in S and val not in hits:\n",
    "                hits.append(val)\n",
    "        return hits\n",
    "\n",
    "    corp_orgs = pick_in(sections[\"corporate\"], \"ORG\")\n",
    "    corp_locs = pick_in(sections[\"corporate\"], \"LOC\")\n",
    "    acad_bg_orgs = pick_in(sections[\"academic_bg\"], \"ORG\")\n",
    "    acad_exp_orgs = pick_in(sections[\"academic_exp\"], \"ORG\")\n",
    "    acad_exp_locs = pick_in(sections[\"academic_exp\"], \"LOC\")\n",
    "\n",
    "    # Education (simple regex on academic background section)\n",
    "    education = list({m.group(0).upper().replace(\".\", \"\") for m in DEGREE_PAT.finditer(sections[\"academic_bg\"])})\n",
    "\n",
    "    # Subjects (keywords from academic experience)\n",
    "    subjects = list({m.group(0).title() for m in SUBJECT_PAT.finditer(sections[\"academic_exp\"])})\n",
    "\n",
    "    return {\n",
    "        \"Corporate Experience - Location\": corp_locs,\n",
    "        \"Corporate Experience - Organization\": corp_orgs,\n",
    "        \"Academic Background - Organization\": acad_bg_orgs,\n",
    "        \"Academic Background - Education\": education,\n",
    "        \"Academic Experience - Courses\": [],  # optional—can be filled later if you choose\n",
    "        \"Academic Experience - Subjects\": subjects,\n",
    "    }\n",
    "\n",
    "df[\"property_dict\"] = df.apply(build_property_dict, axis=1)\n",
    "df[\"property_dict\"].head(2).to_dict()\n",
    "\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "org_counts = Counter([e[1] for row in df[\"normalized_entities\"] for e in row if e[0] == \"ORG\"])\n",
    "loc_counts = Counter([e[1] for row in df[\"normalized_entities\"] for e in row if e[0] == \"LOC\"])\n",
    "\n",
    "print(\"Top ORGs:\", org_counts.most_common(10))\n",
    "print(\"Top LOCs:\", loc_counts.most_common(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b388be",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"../data/processed/teachers_db_cleaned.parquet\"\n",
    "df.to_parquet(output_path, index=False)\n",
    "print(f\"Saved cleaned dataset to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b1a7c2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Professor 1 ---\n",
      "Corporate Experience - Organization: ['Instituto Cervantes', 'European Union Association Of National Cultural Institutes', 'Hispanic Observatory', 'Ronda Energy Ltd']\n",
      "Corporate Experience - Location: ['Istanbul', 'Dublin', 'London', 'Turkey', 'Ireland', 'United Kingdom', 'United Kingdom', 'London']\n",
      "Academic Background - Organization: ['Antony S College', 'University College', 'Rbonne University', 'Ortega Y Gasset University Institute', 'University College']\n",
      "Academic Background - Education: ['B.A', 'M.A']\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: ['History', 'International Relations']\n",
      "\n",
      "--- Professor 2 ---\n",
      "Corporate Experience - Organization: []\n",
      "Corporate Experience - Location: []\n",
      "Academic Background - Organization: []\n",
      "Academic Background - Education: ['Bachelor in physics', 'Ph.D']\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: []\n",
      "\n",
      "--- Professor 3 ---\n",
      "Corporate Experience - Organization: ['Environmental & Building Physics', 'Sustainability And Energy Consulting', 'Arup Spain', 'Distrito Castellana Norte', 'National Labs', 'National Research Centre For Energy Environmental And Technology', 'National Centre Of Renewable Energy', 'Research & Development', 'Energy Engineering', 'University Of Oviedo', 'Energy Engineering', 'Technical University Of Valencia', 'Uned University']\n",
      "Corporate Experience - Location: ['Nigeria', 'Venezuela National Football Stadium', 'Madrid']\n",
      "Academic Background - Organization: []\n",
      "Academic Background - Education: []\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: []\n",
      "\n",
      "--- Professor 4 ---\n",
      "Corporate Experience - Organization: ['Vinces Consulting', 'Latham & Watkins Ll']\n",
      "Corporate Experience - Location: []\n",
      "Academic Background - Organization: ['Universidad Carlos Iii', 'University Of London', 'Universidad Pontificia De Comillas', 'Universidad Pontificia Comillas']\n",
      "Academic Background - Education: ['LLM', 'Ph.D']\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: ['Business Administration', 'Comparative and International Dispute Resolution at Queen Mary', 'Law &amp', 'London']\n",
      "\n",
      "--- Professor 5 ---\n",
      "Corporate Experience - Organization: []\n",
      "Corporate Experience - Location: []\n",
      "Academic Background - Organization: ['Universidad Autónoma de Madrid', 'Cum Laude', 'IE', 'Universidad Autónoma de Madrid', 'Thomson Reuters', 'Simmons & Simmons Crime Bulletin', 'Supreme Court', 'Simmons & Simmons Crime Bulletin']\n",
      "Academic Background - Education: ['Master in Corporate Law', 'PHD']\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: ['Advanced Studies', 'Corporate Law', 'Laws', 'Spain']\n",
      "\n",
      "--- Professor 6 ---\n",
      "Corporate Experience - Organization: ['Pompeu Fabra University', 'Columbia University', 'Harvard Kennedy School Of Government', 'IESE Business School', 'Center For Higher Studies Of National Defense', 'Ministry Of Industry', 'Universities And Business Schools', 'London School Of Economics', 'Political Science', 'Max Plank Society', 'United Nations', 'Ipslink Group', 'London Stock Exchange']\n",
      "Corporate Experience - Location: ['United States', 'United States', 'Europe', 'North America', 'Africa']\n",
      "Academic Background - Organization: []\n",
      "Academic Background - Education: []\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: []\n",
      "\n",
      "--- Professor 7 ---\n",
      "Corporate Experience - Organization: ['General Electric', 'Omnicom Media Group']\n",
      "Corporate Experience - Location: ['Fifth Avenue Presbyterian Church Of', 'New York']\n",
      "Academic Background - Organization: ['Columbia University', 'Columbia University', 'University Of Colorado']\n",
      "Academic Background - Education: ['MA', 'MBA', 'PhD']\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: ['Colorado', 'English Literature and Psychology', 'Organizational Psychology']\n",
      "\n",
      "--- Professor 8 ---\n",
      "Corporate Experience - Organization: ['IE', 'IE', 'IE', 'IE', 'Business And Product Development', 'IE', 'Andritz Hydro']\n",
      "Corporate Experience - Location: []\n",
      "Academic Background - Organization: ['IE', 'IE', 'Universidad Metropolitana']\n",
      "Academic Background - Education: ['Master in Digital Transformation and Innovation Leadership', 'Master in Market Research and Consumer Behavior']\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: ['Digital Transformation and Innovation Leadership', 'Market Research and Consumer Behavior', 'Science in Business Administration']\n",
      "\n",
      "--- Professor 9 ---\n",
      "Corporate Experience - Organization: ['Cabinet Office', 'Ministry Of Education', 'Freshfields Bruckhaus Deringer Llp', 'Peace Justice And Strong Institutions']\n",
      "Corporate Experience - Location: ['Rome', 'Italy', 'Milan']\n",
      "Academic Background - Organization: ['Academic Back', 'And Social', 'Cconi University', 'Cconi University']\n",
      "Academic Background - Education: ['PhD']\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: ['Arts in Law', 'Business and Social Law']\n",
      "\n",
      "--- Professor 10 ---\n",
      "Corporate Experience - Organization: ['Detail Commercial Solicitors', 'The Online Publishers Limited', 'Construction Kaiser Limited', 'Gmh Luxury', 'Real Estate Developers', 'IE', 'Nigerian Alumni Association', 'Intellifin Solutions Limited', 'Founders Carbon Network', 'Ebola Containment Trust Fund', 'Copperbelt Energy Corporation Plc', 'Nigerian Bar Association', 'Nigerian Security Printing & Minting Company', 'General P', 'Swiss Chamber Of Commerce', 'Swiss Chamber Of Commerce', 'West African Glass Industry Plc']\n",
      "Corporate Experience - Location: ['Lagos Nigeria', 'Delaware', 'United States', 'Nigeria', 'Nigeria', 'Nigeria', 'Nigeria']\n",
      "Academic Background - Organization: ['Institute For Public Private Partnerships', 'IE', 'Northwestern University', 'Chartered Institute Of Arbitrators', 'Nigerian Bar Association', 'University Of Benin', 'Columbia Business School', 'Wharton Business School', 'University Of Pennsylvania']\n",
      "Academic Background - Education: ['LLM']\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: ['Arbitrators', 'Benin', 'Business Administration', 'Pennsylvania']\n",
      "\n",
      "--- Professor 11 ---\n",
      "Corporate Experience - Organization: ['American Institute Of Oratory & Learship', 'D Micro Spain', 'Secuware Inc', 'D Micro', 'D Micro', 'Mplutense University Of Madrid', 'Communications Software', 'Universidad Politécnica Madrid', 'Of Peak Performance', 'Stanford University']\n",
      "Corporate Experience - Location: ['Portugal', 'Silicon Valley', 'Silicon Valley', 'Spain', 'Spain', 'Portugal']\n",
      "Academic Background - Organization: []\n",
      "Academic Background - Education: []\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: []\n",
      "\n",
      "--- Professor 12 ---\n",
      "Corporate Experience - Organization: ['Mea & Apac', 'Vioral Economics Observatory Of Cemad', 'Experience Team', 'Business Consulting', 'Inmerco Marketing', 'Mints & Brains']\n",
      "Corporate Experience - Location: ['Beway', 'Spain', 'Spain', 'Spain', 'Spain', 'Spain']\n",
      "Academic Background - Organization: ['IE', 'Science And Administration', 'Iversitat Autnoma De Barcelona', 'Iversitat De Valencia', 'Iversitat De Valencia', 'University Paris Ouest Nanterre La Défense']\n",
      "Academic Background - Education: []\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: ['Marketing Research and Consumer Behavior', 'Paris', 'Political Science and Administration', 'Sociology']\n",
      "\n",
      "--- Professor 13 ---\n",
      "Corporate Experience - Organization: ['Ministry Of Economics And Competitiveness', 'Directorate General Of Scientific Research', 'Industry Innovation And Infraest']\n",
      "Corporate Experience - Location: ['Switzerland', 'Italy', 'Spain']\n",
      "Academic Background - Organization: ['Gpcl Harvard Business School', 'IESE Business School', 'International Capital Market Association', 'Cconi University']\n",
      "Academic Background - Education: ['B.Sc', 'M.Sc', 'Ph.D']\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: ['Economics', 'Management']\n",
      "\n",
      "--- Professor 14 ---\n",
      "Corporate Experience - Organization: ['Spanish Council Of State', 'Council Of State']\n",
      "Corporate Experience - Location: ['Spain', 'Garrigues', 'Spain']\n",
      "Academic Background - Organization: ['Business Administration', 'Universidad Pontificia De Comillas', 'Universidad Pontificia Comillas']\n",
      "Academic Background - Education: []\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: ['Law and Business Administration']\n",
      "\n",
      "--- Professor 15 ---\n",
      "Corporate Experience - Organization: []\n",
      "Corporate Experience - Location: ['Esa E Di', 'Spain', 'Endesa E Distribución', 'Spain']\n",
      "Academic Background - Organization: ['Academic Back', 'Universidad De Sevilla', 'Acultad De Ciencias Económicas Y Empresariales', 'Universidad De Sevilla', 'Munication Engineering', 'Cuela Superior Ingeniería', 'Universidad De Sevilla']\n",
      "Academic Background - Education: ['Master in Marketing']\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: ['Data Science and Big Data', 'Marketing', 'Science', 'Science in Telecommunication Engineering']\n",
      "\n",
      "--- Professor 16 ---\n",
      "Corporate Experience - Organization: ['University Of Oviedo', 'Carlos Iii University', 'Inter American Development Bank', 'Caixabank Research']\n",
      "Corporate Experience - Location: ['Washington Dc', 'United States']\n",
      "Academic Background - Organization: []\n",
      "Academic Background - Education: []\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: []\n",
      "\n",
      "--- Professor 17 ---\n",
      "Corporate Experience - Organization: ['Cloud & Devops', 'Cloud & Devops', 'C4Isr Defense', 'Speech & Sound Group']\n",
      "Corporate Experience - Location: ['Dra']\n",
      "Academic Background - Organization: ['Cyber Security', 'Imf Business School', 'Telecommunications Engineering', 'Universidad Politécnica De Madrid', 'Iversitt Stuttgart', 'Universidad Politécnica De Madrid']\n",
      "Academic Background - Education: ['Bachelor in Telecommunications Engineering', 'M.Sc']\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: ['Information Technology', 'Telecommunications Engineering']\n",
      "\n",
      "--- Professor 18 ---\n",
      "Corporate Experience - Organization: ['Project Code', 'Truck Lagbe', 'Intelligent Machines', 'Telecom Media And Technology Team', 'M & A', 'Santander Corporate And Investment Banking', 'Dc Advisory', 'Investment Banking', '& Associate', 'Gbs Finance', 'Ie Venture Lab Startup', 'M & A', 'Do Corporate Finance']\n",
      "Corporate Experience - Location: ['Bangladesh', 'Bangladesh', 'Bangladesh', 'Spain', 'Spain', 'Spain', 'Spain', 'Spain', 'Middle East', 'Uae', 'Bangladesh']\n",
      "Academic Background - Organization: ['IE', 'Harvard University', 'Uwc Atlantic College']\n",
      "Academic Background - Education: ['Bachelor in Business Administration']\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: ['Business Administration', 'South East Asia']\n",
      "\n",
      "--- Professor 19 ---\n",
      "Corporate Experience - Organization: []\n",
      "Corporate Experience - Location: []\n",
      "Academic Background - Organization: ['Universidad Pontificia De Comillas Icade', 'Universidad Pontificia De Comillas Icade', 'La De', 'Los Gas', 'Fundación Impuestos Y Competitividad', 'Papeles De La Fundación', 'Fundación De Estudios Financieros', 'World Commerce']\n",
      "Academic Background - Education: []\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: ['Business Administration', 'Espa', 'Madrid', 'Spain', 'World Commerce Review']\n",
      "\n",
      "--- Professor 20 ---\n",
      "Corporate Experience - Organization: ['Real Estate Products', 'Stockholm School Of Economics', 'L École Des Hautes Études Commerciales', 'Real Estate Development And Hotel Investment', 'Cornell University', 'IE', 'Ehb Independent Advisors', 'Transaction Advisory Service', 'Transaction Real Estate', 'Hotels Valuations And Corporate Finance', 'Knight Frank', 'Jones Lang Lasalle', 'Women In Real Estate Spain']\n",
      "Corporate Experience - Location: ['Paris']\n",
      "Academic Background - Organization: []\n",
      "Academic Background - Education: []\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: []\n",
      "\n",
      "--- Professor 21 ---\n",
      "Corporate Experience - Organization: []\n",
      "Corporate Experience - Location: []\n",
      "Academic Background - Organization: ['The University Of Texas At', 'The University Of Texas At', 'Hong Kong University Of Science And Technology', 'Hong Kong University Of Science And Technology', 'Sun Yat Sen University']\n",
      "Academic Background - Education: ['B.A', 'M.S', 'MS', 'Ph.D']\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: ['China', 'Global China Studies', 'Government', 'Science and Technology', 'Social Science', 'Sociology in Sun Yat-sen University', 'Statistics', 'Texas at Austin']\n",
      "\n",
      "--- Professor 22 ---\n",
      "Corporate Experience - Organization: []\n",
      "Corporate Experience - Location: []\n",
      "Academic Background - Organization: ['Manchester University', 'IE', 'IE', 'Universidad Autónoma']\n",
      "Academic Background - Education: ['BA', 'MBA', 'PhD']\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: []\n",
      "\n",
      "--- Professor 23 ---\n",
      "Corporate Experience - Organization: ['Dbp Institute', 'General Electric', 'P & G']\n",
      "Corporate Experience - Location: ['Canada', 'Canada', 'India', 'Belgium']\n",
      "Academic Background - Organization: ['Institute Of Corporate Directors', 'Technology Management', 'Esc Lille', 'Kellogg School Of Management', 'Information Technology', 'Industrial Engineering', 'Mysore University']\n",
      "Academic Background - Education: ['BS', 'MBA', 'MS', 'PhD']\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: ['Corporate Directors', 'Management']\n",
      "\n",
      "--- Professor 24 ---\n",
      "Corporate Experience - Organization: ['Multiverse Computing', 'Santander Consumer Finance', 'Banco Santander', 'Andersen Consulting', 'Horváth And Partners']\n",
      "Corporate Experience - Location: ['Spain', 'Spain', 'Spain', 'Spain', 'Spain', 'Spain']\n",
      "Academic Background - Organization: ['Universidad De Sevilla']\n",
      "Academic Background - Education: ['MSc']\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: ['Business Management']\n",
      "\n",
      "--- Professor 25 ---\n",
      "Corporate Experience - Organization: ['Comunidad De Madrid', 'Business And Digital Transformation', 'Smart Cities', 'Comunidad De Madrid', 'Regional Government Of Madrid', 'Oficina Municipal Del Plan', 'Commercial Parks At', 'Real Estate', 'Madrid City Council', 'Urban Planning Department']\n",
      "Corporate Experience - Location: ['Europe', 'Madrid', 'Commercial', 'Spain', 'Commercial', 'Spain', 'France', 'Germany', 'Italy', 'Belgium', 'Greece', 'Colombia', 'Argentina']\n",
      "Academic Background - Organization: []\n",
      "Academic Background - Education: []\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: []\n",
      "\n",
      "--- Professor 26 ---\n",
      "Corporate Experience - Organization: ['Global Markets Bbva Usa', 'Bva Securities Inc', 'Bbva Global Asset Management Business', 'Bbva Global Equities', 'Santander Investment']\n",
      "Corporate Experience - Location: ['Spain', 'United States', 'United States', 'Spain', 'Spain', 'Americas', 'Spain']\n",
      "Academic Background - Organization: ['Economy And', 'Centro Estudios Monetarios Y Financieros', 'Central Bank Of Spain', 'Industrial Engineering', 'Universidad Politécnica de Madrid']\n",
      "Academic Background - Education: ['Bachelor in Industrial Engineering', 'Master in Economy and Finance']\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: ['Economy and Finance', 'Industrial Engineering', 'Spain']\n",
      "\n",
      "--- Professor 27 ---\n",
      "Corporate Experience - Organization: ['IE', 'IE', 'Ie Brown', 'IE', 'IE']\n",
      "Corporate Experience - Location: []\n",
      "Academic Background - Organization: ['IE', 'IE', 'Industrial Engineering', 'Technical University Of Madrid']\n",
      "Academic Background - Education: ['MBA', 'Ms']\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: ['Madrid']\n",
      "\n",
      "--- Professor 28 ---\n",
      "Corporate Experience - Organization: ['Cic Bank']\n",
      "Corporate Experience - Location: ['France']\n",
      "Academic Background - Organization: ['Rbonne University Business School', 'University Of Paris Mines', 'Conservatoire National Des Arts Et Métiers']\n",
      "Academic Background - Education: ['B.A', 'PhD']\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: ['Business', 'Management Accounting', 'Organization Studies', 'Paris']\n",
      "\n",
      "--- Professor 29 ---\n",
      "Corporate Experience - Organization: ['And Insolvency Area', '& B']\n",
      "Corporate Experience - Location: ['Madrid']\n",
      "Academic Background - Organization: []\n",
      "Academic Background - Education: []\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: []\n",
      "\n",
      "--- Professor 30 ---\n",
      "Corporate Experience - Organization: ['International Financial Centre', 'Ance & Stewards', 'Aifc Acamic Council', 'Sustainable Foresight Institute', 'Lakewell Capital Partners', 'National Investment Corporation', 'National Bank Of Kazakhstan', 'Strategic For', 'Kazakhstan Development Bank', 'Processes & Applications', 'S & P Global', 'World Economic Forum', 'Committee Of Managing Directors', 'Shell International', '& Strategy', 'Mckinsey & Company']\n",
      "Corporate Experience - Location: ['Tana']\n",
      "Academic Background - Organization: ['Academic Back', 'University Of Cambridge', 'Geneva School Of Diplomacy & International Relations', 'Strategy & Finance', 'University Of London', 'Bility Lears', 'Cambridge University', 'Belgian American Educational Foundation', 'Harvard Business School', 'Management And Business Administration', 'Boston University', 'Computer Information Systems', 'Boston University', 'National Association Of Corporate Directors', 'Nacd Board', 'Institute Of Directors', 'Chartered Governance Institute', 'Chartered Governance Professional', 'Singapore Institute Of Directors', 'Stanford Directors Consortium']\n",
      "Academic Background - Education: ['Doctor of International Relations', 'MBA', 'MSc', 'PhD']\n",
      "Academic Experience - Courses: []\n",
      "Academic Experience - Subjects: ['Cambridge', 'Corporate Directors', 'Diplomacy &amp', 'Directors', 'Directorship', 'International Relations', 'London']\n"
     ]
    }
   ],
   "source": [
    "# ---- Build dictionaries per professor from sectioned entities ----\n",
    "def to_lists(section_entities):\n",
    "    orgs = [e[1] for e in section_entities if e[0] == \"ORG\"]\n",
    "    locs = [e[1] for e in section_entities if e[0] == \"LOC\"]\n",
    "    return orgs, locs\n",
    "\n",
    "def build_professor_dict_row(row):\n",
    "    corp_orgs, corp_locs = to_lists(row[\"norm_corp\"])\n",
    "    acadexp_orgs, acadexp_locs = to_lists(row[\"norm_acadexp\"])\n",
    "    acadbg_orgs, acadbg_locs = to_lists(row[\"norm_acadbg\"])\n",
    "\n",
    "    return {\n",
    "        \"Corporate Experience - Organization\": corp_orgs,\n",
    "        \"Corporate Experience - Location\": corp_locs,\n",
    "        \"Academic Background - Organization\": acadbg_orgs,\n",
    "        \"Academic Background - Education\": [],    # optional enhancement later (regex keywords)\n",
    "        \"Academic Experience - Courses\": [],      # optional\n",
    "        \"Academic Experience - Subjects\": [],     # optional\n",
    "        # You can also include acadexp_locs if you want:\n",
    "        # \"Academic Experience - Location\": acadexp_locs\n",
    "    }\n",
    "\n",
    "df[\"professor_dict\"] = df.apply(build_professor_dict_row, axis=1)\n",
    "\n",
    "# ---- Extract degrees/subjects from the \"Academic Background\" section and\n",
    "# move them out of ORGs into Academic Background - Education ----\n",
    "\n",
    "import re\n",
    "\n",
    "def get_section(text, start_key, stop_keys):\n",
    "    t = text or \"\"\n",
    "    t_low = t.lower()\n",
    "    s = t_low.find(start_key.lower())\n",
    "    if s == -1:\n",
    "        return \"\"\n",
    "    e_candidates = [t_low.find(k.lower(), s+1) for k in stop_keys]\n",
    "    e_candidates = [e for e in e_candidates if e != -1]\n",
    "    e = min(e_candidates) if e_candidates else len(t)\n",
    "    return t[s:e]\n",
    "\n",
    "# Broad degree / credential patterns (English + common ES terms)\n",
    "DEGREE_PAT = re.compile(\n",
    "    r\"\"\"\n",
    "    \\b(\n",
    "        ph\\.?d\\.?|doctor(?:ate)?\\s+of\\s+[A-Za-zÁÉÍÓÚÜÑ&\\-\\s]+|\n",
    "        m\\.?b\\.?a\\.?|m\\.?sc\\.?|m\\.?s\\.?|m\\.?a\\.?|ll\\.?m\\.?|\n",
    "        b\\.?sc\\.?|b\\.?s\\.?|b\\.?a\\.?|\n",
    "        master(?:'s)?\\s+in\\s+[A-Za-zÁÉÍÓÚÜÑ&\\-\\s]+|\n",
    "        bachelor(?:'s)?\\s+in\\s+[A-Za-zÁÉÍÓÚÜÑ&\\-\\s]+|\n",
    "        licenciatura\\s+en\\s+[A-Za-zÁÉÍÓÚÜÑ&\\-\\s]+|\n",
    "        grado\\s+en\\s+[A-Za-zÁÉÍÓÚÜÑ&\\-\\s]+\n",
    "    )\\b\n",
    "    \"\"\",\n",
    "    re.IGNORECASE | re.VERBOSE,\n",
    ")\n",
    "\n",
    "# Light subject extractor: “… in X” or “… of X”\n",
    "SUBJECT_PAT = re.compile(r\"\\b(?:in|of)\\s+([A-Z][A-Za-zÁÉÍÓÚÜÑ&\\-\\s]{3,})\")\n",
    "\n",
    "def split_background_fields(row):\n",
    "    # 1) Get the Academic Background text slice from your cleaned text\n",
    "    bg_text = get_section(\n",
    "        row.get(\"clean_text\", \"\"),\n",
    "        start_key=\"Academic Background\",\n",
    "        stop_keys=[\"Academic Experience\", \"Corporate Experience\"]\n",
    "    )\n",
    "\n",
    "    # 2) Degrees & subjects from the text\n",
    "    degrees = [m.group(0).strip().rstrip(\",.;\") for m in DEGREE_PAT.finditer(bg_text)]\n",
    "    subjects = [m.group(1).strip().rstrip(\",.;\") for m in SUBJECT_PAT.finditer(bg_text)]\n",
    "\n",
    "    # 3) Remove degree-like tokens that leaked into ORG buckets for this professor\n",
    "    d = row[\"professor_dict\"].copy()\n",
    "    ab_orgs = d.get(\"Academic Background - Organization\", [])\n",
    "    cleaned_ab_orgs = []\n",
    "    for org in ab_orgs:\n",
    "        if DEGREE_PAT.search(org) or SUBJECT_PAT.search(org):\n",
    "            continue\n",
    "        cleaned_ab_orgs.append(org)\n",
    "\n",
    "    # 4) Update dictionary\n",
    "    d[\"Academic Background - Organization\"] = cleaned_ab_orgs\n",
    "    d[\"Academic Background - Education\"] = sorted(set(d.get(\"Academic Background - Education\", []) + degrees))\n",
    "    # Optional: add subjects here (or keep for \"Academic Experience - Subjects\" later)\n",
    "    d[\"Academic Experience - Subjects\"] = sorted(set(d.get(\"Academic Experience - Subjects\", []) + subjects))\n",
    "\n",
    "    return d\n",
    "\n",
    "df[\"professor_dict\"] = df.apply(split_background_fields, axis=1)\n",
    "\n",
    "\n",
    "import random\n",
    "for i, d in enumerate(df[\"professor_dict\"].sample(30, random_state=42).to_list(), 1):\n",
    "    print(f\"\\n--- Professor {i} ---\")\n",
    "    for k, v in d.items():\n",
    "        print(f\"{k}: {v}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
